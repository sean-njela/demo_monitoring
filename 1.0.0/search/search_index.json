{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\ude80 Monitoring with Prometheus \u2014 A Personal Project","text":"<p>Welcome to my Prometheus documentation project \u2014 a personal initiative to showcase deep expertise in monitoring, observability, and cloud-native systems.  </p> <p>This site is structured as a complete guide to Prometheus, blending fundamentals, hands-on examples, best practices, and advanced topics. It is designed for engineers, SREs, and learners who want to understand Prometheus from zero to production-ready scale.  </p>"},{"location":"#project-purpose","title":"\ud83c\udfaf Project Purpose","text":"<ul> <li>\u2705 Demonstrate expert knowledge in Prometheus, observability, and the monitoring ecosystem.  </li> <li>\ud83d\udcda Provide a world-class learning resource that assumes no prior knowledge.  </li> <li>\ud83e\uddd1\u200d\ud83d\udcbc Serve as a portfolio piece highlighting my technical writing, system design, and DevOps skills.  </li> </ul>"},{"location":"#quick-overview-of-prometheus","title":"\ud83e\udded Quick Overview of Prometheus","text":"<p>Prometheus is an open-source monitoring and alerting toolkit that: - \ud83d\udd27 Collects metrics from applications, systems, and services. - \ud83d\udcca Stores them in a purpose-built time-series database (TSDB). - \ud83d\udd0d Provides a powerful query language (PromQL) for analysis. - \ud83d\udd14 Integrates with Alertmanager for notifications. - \u26a1 Pairs with Grafana for visualization.  </p>"},{"location":"#getting-started","title":"\u26a1 Getting Started","text":"<p>Jump into the Quick Start guide to see Prometheus in action: - Install and run Prometheus. - Scrape your first target. - Query data using PromQL. - Visualize metrics in Grafana. - Trigger a simple alert.  </p>"},{"location":"#architecture-components","title":"\ud83d\udcd0 Architecture &amp; Components","text":"<p>This project explains Prometheus from the ground up:</p> <ul> <li>Core Concepts \u2192 Targets, exporters, metrics, labels.  </li> <li>Prometheus Server \u2192 Scraping, TSDB, querying.  </li> <li>Alertmanager \u2192 Alerts and routing.  </li> <li>Grafana \u2192 Visualization.  </li> <li>Scaling \u2192 Thanos, Cortex, federation, long-term storage.  </li> </ul> <p>Explore diagrams and workflows in Architecture.</p>"},{"location":"#documentation-roadmap","title":"\ud83d\udcda Documentation Roadmap","text":"<p>The site is organized as a step-by-step progression:</p> <ul> <li>Quick Start \u2192 Setup, scrape your first metrics, build intuition.  </li> <li>Architecture \u2192 Understand internals and ecosystem.  </li> <li>PromQL &amp; Features \u2192 Querying, alerting, exporters.  </li> <li>Scaling &amp; Best Practices \u2192 Long-term storage, high-cardinality handling.  </li> <li>About Me \u2192 My background, expertise, and contact.  </li> </ul>"},{"location":"#example-use-cases","title":"\ud83e\uddea Example Use Cases","text":"<p>Prometheus is used widely for:  </p> <ul> <li>\ud83d\udda5\ufe0f System Monitoring \u2192 CPU, memory, disk metrics.  </li> <li>\ud83d\udce6 Kubernetes Monitoring \u2192 Nodes, pods, cluster health.  </li> <li>\ud83d\udee0\ufe0f Application Monitoring \u2192 API traffic, error rates, latency.  </li> <li>\ud83d\udd14 Alerting \u2192 Incident detection, anomaly detection.  </li> </ul> <p>These examples are included as practical demos in this documentation.</p>"},{"location":"#useful-links","title":"\ud83d\udd17 Useful Links","text":"<ul> <li>\u26a1 Getting Started </li> <li>\ud83d\udcca System Architecture </li> <li>\ud83d\udcdd PromQL &amp; Features </li> <li>\ud83e\uddd1\u200d\ud83d\udcbc About Me </li> </ul>"},{"location":"#about-this-project","title":"\ud83d\udca1 About This Project","text":"<p>This documentation is a personal showcase of expertise in monitoring and DevOps. It combines:</p> <ul> <li>Technical accuracy  </li> <li>Hands-on best practices  </li> <li>Clear explanations for all levels  </li> </ul> <p>License: MIT </p> <p>Maintained by Sean Njela.  </p>"},{"location":"disclaimer/","title":"\ud83d\udcc4 Disclaimer","text":"<p>The information and resources provided in this project are intended for educational and informational purposes only.</p>"},{"location":"disclaimer/#no-warranty","title":"\ud83d\udea7 No Warranty","text":"<p>This project is provided \"as is\" without warranty of any kind\u2014express or implied. While I have made every effort to ensure the accuracy and reliability of the information, I make no guarantees about:</p> <ul> <li>Suitability for any specific purpose  </li> <li>Completeness or accuracy of configurations or scripts  </li> <li>Security of infrastructure or deployments  </li> </ul> <p>Use at your own risk.</p>"},{"location":"disclaimer/#for-personal-use-learning","title":"\ud83d\udee0 For Personal Use / Learning","text":"<p>This project is part of a personal portfolio and is primarily intended to:</p> <ul> <li>Demonstrate practical implementation of technical concepts  </li> <li>Serve as a sandbox for experimentation  </li> <li>Be a reference for future personal or professional projects  </li> </ul> <p>It is not intended for production use without proper review and adaptation.</p>"},{"location":"disclaimer/#security-and-sensitive-data","title":"\ud83d\udd10 Security and Sensitive Data","text":"<p>Do not reuse any credentials, tokens, secrets, or keys shown in this project. They are either fake, expired, or meant only for demonstration.</p> <p>Always handle secrets securely and follow best practices for secret management (e.g., environment variables, sealed secrets, vaults).</p>"},{"location":"disclaimer/#opinions-are-my-own","title":"\ud83d\udcac Opinions Are My Own","text":"<p>All opinions, techniques, and practices shared here reflect my personal learning journey and are not affiliated with or endorsed by any employer, client, or organization.</p>"},{"location":"disclaimer/#license","title":"\ud83d\udcdc License","text":"<p>This project is licensed under the MIT, which permits reuse, modification, and distribution\u2014with proper attribution.</p>"},{"location":"disclaimer/#contact","title":"\ud83d\udceb Contact","text":"<p>If you spot issues, risks, or have questions about how something works, feel free to reach out:</p> <ul> <li>\ud83d\udce7 seannjela@outlook.com </li> <li>\ud83d\udc19 GitHub Issues</li> </ul>"},{"location":"0-quickstart/0-prerequisites/","title":"Prerequisites","text":"<p>This project uses Devbox to manage the development environment. Devbox provides a consistent, isolated environment with all the necessary CLI tools pre-installed.</p>"},{"location":"0-quickstart/0-prerequisites/#docker","title":"Docker","text":"<ul> <li>Follow the installation instructions for your operating system.</li> </ul> <p>The rest of the tools are already installed in the devbox environment</p>"},{"location":"0-quickstart/0-prerequisites/#devbox","title":"Devbox","text":"<ul> <li>Follow the installation instructions for your operating system.</li> </ul>"},{"location":"0-quickstart/0-prerequisites/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/sean-njela/demo_monitoring.git\ncd demo_monitoring\n</code></pre>"},{"location":"0-quickstart/0-prerequisites/#start-the-devbox-environment-and-poetry-environment","title":"Start the Devbox Environment and poetry environment","text":"<pre><code>devbox shell # Start the devbox environment (this will also start the poetry environment)\npoetry install # Install dependencies\npoetry env activate # use the output to activate the poetry environment ( ONLY IF DEVBOX DOES NOT ACTIVATE THE ENVIRONMENT)\n</code></pre> <p>Note</p> <p>The first time you run <code>devbox shell</code>, it will take a few minutes to install the necessary tools. But after that it will be much faster.</p>"},{"location":"0-quickstart/1-getting-started/","title":"\ud83d\ude80 Getting Started","text":"<p>Welcome! This section will walk you through how to get the project up and running on your local machine or development environment.</p>"},{"location":"0-quickstart/1-getting-started/#prerequisites","title":"\ud83e\uddf0 Prerequisites","text":"<p>Before you begin, ensure you have the following installed all the requirements. See the Prerequisites section for detailed instructions on installing these tools.</p>"},{"location":"0-quickstart/1-getting-started/#walkthrough","title":"\u2705 Walkthrough","text":"<p>After everything is wired up, you can run the following commands:</p> <pre><code>task dev # this one command will run all commands necessary to setup the environment\n</code></pre> <p>This will start the devbox environment and poetry environment and install all dependencies. And that is all you need to do to get started. (Yes, really.)</p> <p>In a seperate terminal, run:</p> <pre><code>task docs # serve docs locally\n</code></pre> <p>Docs available at: http://127.0.0.1:8000/</p> <p>All other commands are in the form of tasks. The project task file is <code>Taskfile.yaml</code>.</p> <pre><code>task --list-all # to see all project tasks\ntask &lt;command&gt; # usage\n</code></pre> <p>The project also uses gitflow for version control with gh-pages deployment automation. This is optional but you can also automate it using the <code>Taskfile.gitflow.yaml</code> file.</p> <pre><code>task -t Taskfile.gitflow.yaml --list-all # to see all gitflow tasks\ntask -t Taskfile.gitflow.yaml &lt;command&gt; # usage\n</code></pre> <p>See the Tasks section for more information on all tasks.</p>"},{"location":"0-quickstart/1-getting-started/#cleanup","title":"\ud83e\uddfc Cleanup","text":"<p>To tear everything down after testing:</p> <pre><code>task cleanup-dev # to cleanup everything running locally\ntask cleanup-prod # to cleanup everything running in production (IF YOU USED ANY PROD. WORKFLOWS)\ntask cleanup-all # to cleanup everything (local and production)\n</code></pre>"},{"location":"0-quickstart/1-getting-started/#need-help","title":"\u2753 Need Help?","text":"<p>If you get stuck:</p> <ul> <li>Check the Troubleshooting guide.</li> <li>Open an issue on GitHub</li> </ul> <p>Happy building! \ud83d\udee0</p>"},{"location":"1-architecture/0-overview/","title":"\ud83e\uddf1 System Architecture Overview","text":"<p>This section provides a high-level overview of the monitoring and observability stack used in this project. It highlights the core components, their responsibilities, and how they work together to provide end-to-end monitoring, alerting, and visualization for modern infrastructure and applications.</p>"},{"location":"1-architecture/0-overview/#design-philosophy","title":"\ud83d\udcd0 Design Philosophy","text":"<p>Our monitoring stack is built around a few guiding principles:</p> <ul> <li>Modular and Composable \u2192 Each tool has a clear responsibility (metrics, alerts, visualization).</li> <li>Cloud-Native \u2192 Runs seamlessly in containerized/Kubernetes environments.</li> <li>Automation-First \u2192 Designed for IaC and CI/CD pipelines.</li> <li>Production-Ready \u2192 Secure defaults, scalable, and extensible.</li> <li>Developer-Friendly \u2192 Easy to run locally (e.g., with Docker Compose or Kind).</li> </ul>"},{"location":"1-architecture/0-overview/#core-components","title":"\ud83e\udde9 Core Components","text":""},{"location":"1-architecture/0-overview/#1-metrics-collection-cadvisor","title":"1. Metrics Collection (cAdvisor)","text":"<ul> <li>cAdvisor runs on each node to collect container-level resource usage (CPU, memory, disk, network).</li> <li>Integrated with Kubernetes via the kubelet.</li> <li>Exposes metrics at <code>/metrics</code> in Prometheus format.</li> </ul>"},{"location":"1-architecture/0-overview/#2-monitoring-storage-prometheus","title":"2. Monitoring &amp; Storage (Prometheus)","text":"<ul> <li>Prometheus scrapes metrics from cAdvisor, node exporters, and other exporters.</li> <li>Stores data in its time-series database (TSDB).</li> <li>Provides the PromQL query language for powerful analysis.</li> </ul>"},{"location":"1-architecture/0-overview/#3-visualization-grafana","title":"3. Visualization (Grafana)","text":"<ul> <li>Grafana connects to Prometheus and displays metrics in dashboards.</li> <li>Includes pre-built dashboards for containers, nodes, and Kubernetes clusters.</li> <li>Enables engineers to explore, visualize, and share insights.</li> </ul>"},{"location":"1-architecture/0-overview/#4-alerting-alertmanager","title":"4. Alerting (Alertmanager)","text":"<ul> <li>Alertmanager receives alerts from Prometheus.</li> <li>Handles deduplication, grouping, and routing of alerts.</li> <li>Sends notifications via Slack, Email, PagerDuty, etc.</li> </ul>"},{"location":"1-architecture/0-overview/#architecture-diagram","title":"\ud83d\udd00 Architecture Diagram","text":"<pre><code>flowchart TD\n\n    subgraph Node[\"Kubernetes Node / Host\"]\n        subgraph Containers[\"Containers\"]\n            A1[\"App Container A\"]\n            A2[\"App Container B\"]\n        end\n        C[\"cAdvisor\"]\n    end\n\n    A1 --&gt; C\n    A2 --&gt; C\n\n    C --&gt; P[\"Prometheus\"]\n    P --&gt; G[\"Grafana Dashboards\"]\n    P --&gt; A[\"Alertmanager\"]\n\n    G --&gt; U[\"User (SRE/DevOps)\"]\n    A --&gt; U</code></pre>"},{"location":"1-architecture/0-overview/#data-control-flow","title":"\ud83d\udd04 Data / Control Flow","text":"<ol> <li>Containers run applications and consume resources.</li> <li>cAdvisor collects resource usage metrics from the kernel (cgroups).</li> <li>Prometheus scrapes metrics from cAdvisor (and other exporters).</li> <li>Prometheus TSDB stores time-series data.</li> <li>Grafana queries Prometheus to render dashboards and visualizations.</li> <li>Prometheus rules evaluate alert conditions (e.g., CPU &gt; 90%).</li> <li>Alertmanager routes alerts to Slack/email.</li> <li>Users (SRE/DevOps) view dashboards and respond to alerts.</li> </ol>"},{"location":"1-architecture/0-overview/#related-pages","title":"\ud83e\udded Related Pages","text":"<ul> <li>Quickstart: Getting Started</li> <li>Prometheus Notes</li> <li>cAdvisor Notes</li> <li>Grafana Notes</li> <li>Alertmanager Notes</li> </ul>"},{"location":"2-project/alertmanager/","title":"\ud83d\udea8 What is Alertmanager?","text":"<p>Alertmanager is the alerting component of the Prometheus ecosystem. It is responsible for handling alerts generated by Prometheus servers and sending notifications to external systems.</p> <p>It provides:</p> <ul> <li>Routing \u2192 decide where alerts go (Slack, Email, PagerDuty, etc.)</li> <li>Grouping \u2192 combine related alerts into a single notification</li> <li>Silencing \u2192 temporarily mute alerts during maintenance</li> <li>Deduplication \u2192 avoid spamming users with repeated alerts</li> </ul> <p>\ud83d\udc49 Prometheus detects the problem, but Alertmanager tells humans (or systems) about it.</p>"},{"location":"2-project/alertmanager/#why-do-we-need-alertmanager","title":"\ud83e\uddd0 Why Do We Need Alertmanager?","text":"<p>Without Alertmanager:</p> <ul> <li>Prometheus can trigger alerts, but it doesn\u2019t know how to notify people.</li> <li>Each alert would generate raw, unorganized messages.</li> </ul> <p>Challenges Alertmanager solves:</p> <ul> <li>Too many alerts \u2192 group and deduplicate.</li> <li>Wrong people notified \u2192 route to the right team.</li> <li>Alert fatigue \u2192 silence during maintenance.</li> </ul> <p>\ud83d\udc49 It\u2019s the traffic controller for alerts.</p>"},{"location":"2-project/alertmanager/#how-alertmanager-works","title":"\ud83d\udd27 How Alertmanager Works","text":"<ol> <li>Prometheus evaluates alert rules (<code>.rules</code> or <code>.yml</code> files).</li> <li>If a rule fires, Prometheus sends an alert to Alertmanager via HTTP.</li> <li> <p>Alertmanager:</p> <ul> <li>Groups related alerts.</li> <li>Applies routing rules (e.g., critical \u2192 PagerDuty, warnings \u2192 Slack).</li> <li>Sends notifications.</li> </ul> </li> <li> <p>Users acknowledge alerts, silence them if needed, or take action.</p> </li> </ol>"},{"location":"2-project/alertmanager/#architecture-overview","title":"\ud83d\udd17 Architecture Overview","text":"<pre><code>+-------------------+\n| Prometheus Server |  --&gt;  Fires alerts\n+---------+---------+\n          |\n          v\n+---------+---------+\n| Alertmanager      |\n| - Grouping        |\n| - Routing         |\n| - Silencing       |\n| - Deduplication   |\n+---------+---------+\n   |   |   |   |\n   v   v   v   v\n Email Slack PagerDuty Webhook\n</code></pre>"},{"location":"2-project/alertmanager/#alert-flow-from-prometheus-alertmanager-user","title":"\ud83d\udd04 Alert Flow: From Prometheus \u2192 Alertmanager \u2192 User","text":"<pre><code>sequenceDiagram\n    participant Prom as Prometheus\n    participant AM as Alertmanager\n    participant User as User (SRE/DevOps)\n\n    Prom-&gt;&gt;AM: Send alert (HTTP POST)\n    AM-&gt;&gt;AM: Group, Deduplicate, Silence\n    AM-&gt;&gt;User: Send notification (Slack/Email/PagerDuty)\n    User-&gt;&gt;AM: Silence/Ack alert (optional)</code></pre>"},{"location":"2-project/alertmanager/#example-alert-rule-in-prometheus","title":"\ud83d\udcdc Example Alert Rule in Prometheus","text":"<pre><code>groups:\n  - name: node.rules\n    rules:\n      - alert: HighCPUUsage\n        expr: rate(node_cpu_seconds_total{mode=\"user\"}[1m]) &gt; 0.9\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High CPU usage on {{ $labels.instance }}\"\n          description: \"CPU usage &gt; 90% for more than 2 minutes.\"\n</code></pre> <p>\ud83d\udc49 When this condition is true, Prometheus sends an alert to Alertmanager.</p>"},{"location":"2-project/alertmanager/#alertmanager-configuration","title":"\u2699\ufe0f Alertmanager Configuration","text":"<p>Alertmanager is configured using a YAML file (<code>alertmanager.yml</code>).</p>"},{"location":"2-project/alertmanager/#example-config","title":"Example Config","text":"<pre><code>global:\n  resolve_timeout: 5m\n\nroute:\n  receiver: 'slack-notifications'\n  group_by: ['alertname', 'cluster']\n  group_wait: 30s\n  group_interval: 5m\n  repeat_interval: 3h\n\nreceivers:\n  - name: 'slack-notifications'\n    slack_configs:\n      - channel: '#alerts'\n        send_resolved: true\n        text: \"\ud83d\udd25 Alert: {{ .CommonAnnotations.summary }}\"\n\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'cluster']\n</code></pre>"},{"location":"2-project/alertmanager/#explanation-of-key-fields","title":"\ud83d\udd0e Explanation of Key Fields","text":"<ul> <li>global \u2192 default settings (timeouts, SMTP server, Slack API URL).</li> <li> <p>route \u2192 defines alert routing rules.</p> </li> <li> <p><code>group_by</code> \u2192 group alerts by label.</p> </li> <li><code>group_wait</code> \u2192 wait before sending to group alerts.</li> <li><code>repeat_interval</code> \u2192 resend alert if still firing.</li> <li>receivers \u2192 list of destinations (Slack, email, PagerDuty).</li> <li>inhibit_rules \u2192 suppress lower-priority alerts if a higher one is firing.</li> </ul>"},{"location":"2-project/alertmanager/#notification-integrations","title":"\ud83d\udd14 Notification Integrations","text":"<p>Alertmanager supports many integrations out of the box:</p> <ul> <li>\ud83d\udce7 Email</li> <li>\ud83d\udcac Slack, Microsoft Teams, Discord</li> <li>\ud83d\udcf1 PagerDuty, OpsGenie, VictorOps</li> <li>\u2601\ufe0f Webhook receivers \u2192 integrate with any custom system</li> <li>\ud83d\udd0c Custom receivers via webhooks</li> </ul>"},{"location":"2-project/alertmanager/#features-of-alertmanager","title":"\ud83d\udee0\ufe0f Features of Alertmanager","text":""},{"location":"2-project/alertmanager/#grouping","title":"\u2705 Grouping","text":"<ul> <li>Combine alerts into a single message.</li> <li>Example: instead of 100 pod alerts, one grouped \u201cPodCrashLoopBackOff\u201d alert.</li> </ul>"},{"location":"2-project/alertmanager/#routing","title":"\u2705 Routing","text":"<ul> <li>Send alerts to different teams.</li> <li>Example: Database alerts \u2192 DBA team, Node alerts \u2192 Infra team.</li> </ul>"},{"location":"2-project/alertmanager/#deduplication","title":"\u2705 Deduplication","text":"<ul> <li>If an alert is firing repeatedly, only send once until it\u2019s resolved.</li> </ul>"},{"location":"2-project/alertmanager/#silences","title":"\u2705 Silences","text":"<ul> <li>Mute alerts temporarily (e.g., during maintenance).</li> <li>Configured via API/UI/CLI.</li> </ul>"},{"location":"2-project/alertmanager/#inhibition","title":"\u2705 Inhibition","text":"<ul> <li>Suppress less severe alerts when a higher severity alert is active.</li> <li>Example: Hide \u201cdisk usage warning\u201d if \u201cdisk full critical\u201d is active.</li> </ul>"},{"location":"2-project/alertmanager/#alertmanager-ui","title":"\ud83d\udda5\ufe0f Alertmanager UI","text":"<p>Alertmanager provides a simple web UI (default port <code>:9093</code>) where you can:</p> <ul> <li>View active alerts</li> <li>Add silences</li> <li>Manage alert history</li> <li>Debug routing</li> </ul>"},{"location":"2-project/alertmanager/#security-best-practices","title":"\ud83d\udee1\ufe0f Security Best Practices","text":"<ul> <li>\u274c Don\u2019t expose Alertmanager directly to the internet.</li> <li>\u2705 Put it behind a reverse proxy (Nginx/Traefik).</li> <li>\u2705 Use authentication if exposed.</li> <li>\u2705 Secure communication between Prometheus and Alertmanager with TLS.</li> </ul>"},{"location":"2-project/alertmanager/#key-strengths-of-alertmanager","title":"\ud83d\udd0d Key Strengths of Alertmanager","text":"<ul> <li>Deep Prometheus integration \u2192 native in the ecosystem.</li> <li>Powerful routing \u2192 fine-grained alert delivery.</li> <li>Extensible \u2192 webhooks for custom workflows.</li> <li>Silences &amp; inhibition \u2192 reduce noise &amp; alert fatigue.</li> <li>Open-source &amp; widely adopted \u2192 large community.</li> </ul>"},{"location":"2-project/alertmanager/#limitations-watch-outs","title":"\u26a0\ufe0f Limitations &amp; Watch Outs","text":"<ul> <li>\u274c Limited UI (mostly config-driven).</li> <li>\u274c No built-in escalation policies (PagerDuty is better for escalation chains).</li> <li>\u274c Single binary \u2192 HA requires running multiple instances with a gossip protocol.</li> <li>\u274c Alert storming still possible if rules aren\u2019t well-tuned.</li> </ul>"},{"location":"2-project/alertmanager/#alertmanager-in-the-observability-stack","title":"\ud83d\udce6 Alertmanager in the Observability Stack","text":"<pre><code>flowchart TD\n\n    subgraph Metrics\n        P[Prometheus]\n    end\n\n    subgraph Alerting\n        A[Alertmanager]\n    end\n\n    subgraph Notifications\n        E[Email]\n        S[Slack]\n        PD[PagerDuty]\n        W[Webhook]\n    end\n\n    P --&gt; A\n    A --&gt; E\n    A --&gt; S\n    A --&gt; PD\n    A --&gt; W</code></pre> <p>\ud83d\udc49 Prometheus detects, Alertmanager notifies.</p>"},{"location":"2-project/alertmanager/#alertmanager-cheat-sheet","title":"\ud83e\uddfe Alertmanager Cheat Sheet","text":""},{"location":"2-project/alertmanager/#core-concepts","title":"\u2705 Core Concepts","text":"Term Meaning Alert Condition defined in Prometheus that triggers Receiver Where alerts are sent (Slack, Email, etc.) Route Rules that decide which receiver gets the alert Silence Temporary mute for alerts Inhibition Suppression of lower alerts when higher ones fire Grouping Bundling multiple alerts into one notification"},{"location":"2-project/alertmanager/#example-silence-command","title":"\ud83d\udcdc Example Silence Command","text":"<pre><code>amtool silence add alertname=HighCPUUsage --duration=2h --comment=\"Maintenance window\"\n</code></pre>"},{"location":"2-project/alertmanager/#example-routing-rule","title":"\ud83d\udcca Example Routing Rule","text":"<pre><code>route:\n  receiver: 'team-A'\n  routes:\n    - match:\n        team: 'database'\n      receiver: 'dba-team'\n    - match:\n        team: 'infra'\n      receiver: 'infra-team'\n</code></pre>"},{"location":"2-project/alertmanager/#final-takeaway","title":"\ud83c\udfaf Final Takeaway","text":"<p>Alertmanager is:</p> <ul> <li>The alert distribution hub for Prometheus.</li> <li>Provides routing, grouping, silencing, inhibition.</li> <li>Supports many integrations (Slack, PagerDuty, Email).</li> <li>Essential for production-grade monitoring.</li> </ul> <p>\ud83d\udc49 Think of Prometheus as the doctor detecting the illness, and Alertmanager as the nurse paging the right specialist.</p>"},{"location":"2-project/cadvisor/","title":"cAdvisor","text":""},{"location":"2-project/cadvisor/#what-is-cadvisor","title":"\ud83d\udc33 What is cAdvisor?","text":"<p>cAdvisor (Container Advisor) is an open-source container monitoring tool developed by Google. It runs as a daemon on a host and provides insights into:</p> <ul> <li>Resource usage (CPU, memory, network, disk I/O)</li> <li>Performance characteristics of running containers</li> <li>Per-container statistics in real time</li> </ul> <p>\ud83d\udc49 cAdvisor is often used as a metrics source for Prometheus in Kubernetes and Docker environments.</p> <p>It\u2019s lightweight, designed to run inside a container, and exposes metrics at an HTTP endpoint (<code>/metrics</code>) in Prometheus format.</p>"},{"location":"2-project/cadvisor/#why-do-we-need-cadvisor","title":"\ud83e\uddd0 Why Do We Need cAdvisor?","text":"<p>In modern containerized environments (Docker, Kubernetes):</p> <ul> <li>Containers are ephemeral (come and go quickly).</li> <li>Multiple containers share the same host.</li> <li>We need visibility into resource consumption per container (not just at the host level).</li> </ul> <p>Without cAdvisor:</p> <ul> <li>You can see host metrics (via <code>node_exporter</code>) but not per-container usage.</li> <li>Hard to debug issues like \u201cwhich container is consuming all the CPU?\u201d</li> </ul> <p>\ud83d\udc49 cAdvisor provides fine-grained container-level metrics, making it critical for container monitoring.</p>"},{"location":"2-project/cadvisor/#what-does-cadvisor-monitor","title":"\ud83d\udcca What Does cAdvisor Monitor?","text":"<p>cAdvisor collects and exposes:</p> <ul> <li>CPU usage (total, per core, throttling).</li> <li>Memory usage (working set, cache, limits).</li> <li>Filesystem usage (per container).</li> <li>Network stats (bytes sent/received, packets).</li> <li>Container lifecycle stats (start, stop, restart).</li> <li>Custom labels (Kubernetes adds pod, namespace, container name).</li> </ul>"},{"location":"2-project/cadvisor/#how-cadvisor-works","title":"\ud83d\udd27 How cAdvisor Works","text":"<ol> <li> <p>Runs as a daemon (usually a Docker container).</p> </li> <li> <p>Reads metrics from the Linux kernel cgroups and container runtime (Docker, containerd, CRI-O).</p> </li> <li> <p>Exposes metrics on an HTTP endpoint:</p> </li> <li> <p>JSON API \u2192 <code>/api/v1.3/subcontainers</code> (legacy).</p> </li> <li> <p>Prometheus format \u2192 <code>/metrics</code>.</p> </li> <li> <p>Tools like Prometheus scrape these metrics.</p> </li> <li> <p>Grafana visualizes them in dashboards.</p> </li> </ol>"},{"location":"2-project/cadvisor/#architecture-overview","title":"\ud83d\udd17 Architecture Overview","text":"<pre><code>+-------------------+\n|   Linux Kernel    |\n| (cgroups, stats)  |\n+---------+---------+\n          |\n          v\n+---------+---------+\n|   cAdvisor        |  (container metrics daemon)\n+---------+---------+\n          |\n          v\n+-------------------+\n| /metrics endpoint |  --&gt; Scraped by Prometheus\n+---------+---------+\n          |\n     +----v-----+\n     | Grafana  |   (visualization)\n     +----------+\n</code></pre>"},{"location":"2-project/cadvisor/#metric-flow-from-container-cadvisor-prometheus-grafana","title":"\ud83d\udd04 Metric Flow: From Container \u2192 cAdvisor \u2192 Prometheus \u2192 Grafana","text":"<pre><code>sequenceDiagram\n    participant Cont as Container\n    participant Kernel as Linux cgroups\n    participant Cad as cAdvisor (/metrics)\n    participant Prom as Prometheus\n    participant Graf as Grafana\n    participant User as DevOps/SRE\n\n    Cont-&gt;&gt;Kernel: Resource usage (CPU, mem, I/O)\n    Cad-&gt;&gt;Kernel: Collect stats via cgroups\n    Prom-&gt;&gt;Cad: Scrape /metrics\n    Prom-&gt;&gt;Prom: Store in TSDB\n    Graf-&gt;&gt;Prom: Query metrics\n    Prom--&gt;&gt;Graf: Return data\n    Graf--&gt;&gt;User: Show dashboards</code></pre>"},{"location":"2-project/cadvisor/#prometheus-cadvisor-architecture","title":"\ud83c\udfd7\ufe0f Prometheus + cAdvisor Architecture","text":"<pre><code>flowchart TD\n\n    subgraph Containers[\"Running Containers (Docker/K8s)\"]\n        C1[\"Container A\"]\n        C2[\"Container B\"]\n        C3[\"Container C\"]\n    end\n\n    subgraph Kernel[\"Linux Kernel (cgroups, namespaces)\"]\n        M1[\"CPU usage\"]\n        M2[\"Memory usage\"]\n        M3[\"Disk I/O\"]\n        M4[\"Network I/O\"]\n    end\n\n    Containers --&gt; Kernel\n\n    subgraph cAdvisor[\"cAdvisor Daemon (per-node)\"]\n        Cad[\"/metrics endpoint\"]\n    end\n\n    Kernel --&gt; Cad\n\n    subgraph Prometheus[\"Prometheus Server\"]\n        P[\"Scrape &amp; Store Metrics (TSDB)\"]\n    end\n\n    Cad --&gt; P\n\n    subgraph Grafana[\"Grafana Dashboards\"]\n        G[\"Visualize Metrics\"]\n    end\n\n    Prometheus --&gt; G\n\n    subgraph Alertmanager[\"Alertmanager\"]\n        A[\"Send Alerts (Slack, Email, PagerDuty)\"]\n    end\n\n    Prometheus --&gt; A</code></pre>"},{"location":"2-project/cadvisor/#explanation-of-the-flow","title":"\ud83d\udd0e Explanation of the Flow","text":"<ol> <li>Containers \u2192 generate resource usage.</li> <li>Linux Kernel (cgroups) \u2192 tracks CPU, memory, disk, and network per container.</li> <li>cAdvisor \u2192 collects these stats and exposes them at <code>/metrics</code>.</li> <li>Prometheus \u2192 scrapes cAdvisor metrics regularly and stores them in its TSDB.</li> <li>Grafana \u2192 queries Prometheus for dashboards (per-container CPU/memory, etc.).</li> <li>Alertmanager \u2192 triggers alerts if rules match (e.g., container using &gt;90% memory).</li> </ol> <p>\ud83d\udc49 This stack gives complete visibility into container performance.</p>"},{"location":"2-project/cadvisor/#kubernetes-cadvisor-prometheus-architecture","title":"\ud83c\udfd7\ufe0f Kubernetes + cAdvisor + Prometheus Architecture","text":"<pre><code>flowchart TD\n\n    subgraph Node[\"Kubernetes Node\"]\n        subgraph Pods[\"Pods &amp; Containers\"]\n            P1[\"Pod A: Container A1, A2\"]\n            P2[\"Pod B: Container B1\"]\n        end\n\n        subgraph Kubelet[\"Kubelet\"]\n            Cad[\"cAdvisor (built-in)\"]\n        end\n\n        Kernel[\"Linux Kernel (cgroups, namespaces)\"]\n    end\n\n    Pods --&gt; Kernel\n    Kernel --&gt; Cad\n\n    subgraph Prometheus[\"Prometheus Server\"]\n        P[\"Scrape &amp; Store Metrics\"]\n    end\n\n    Cad --&gt; P\n\n    subgraph Grafana[\"Grafana Dashboards\"]\n        G[\"Visualize Metrics\"]\n    end\n\n    Prometheus --&gt; G\n\n    subgraph Alertmanager[\"Alertmanager\"]\n        A[\"Send Alerts (Slack, Email, PagerDuty)\"]\n    end\n\n    Prometheus --&gt; A</code></pre>"},{"location":"2-project/cadvisor/#explanation-of-the-kubernetes-flow","title":"\ud83d\udd0e Explanation of the Kubernetes Flow","text":"<ol> <li>Pods (containers) run on each node.</li> <li>Linux kernel (cgroups) tracks per-container resource usage (CPU, memory, I/O).</li> <li> <p>Kubelet runs on every node and integrates cAdvisor internally.</p> </li> <li> <p>Exposes metrics at:</p> <ul> <li><code>/metrics/cadvisor</code> \u2192 container-level</li> <li><code>/metrics</code> \u2192 node &amp; kubelet metrics</li> <li>Prometheus scrapes kubelet endpoints across all nodes.</li> <li>Grafana builds dashboards (per-pod, per-container, per-namespace).</li> <li>Alertmanager notifies when resource thresholds are breached.</li> </ul> </li> </ol> <p>\ud83d\udc49 In Kubernetes, you don\u2019t usually run standalone cAdvisor. Instead, kubelet already provides cAdvisor-powered metrics.</p>"},{"location":"2-project/cadvisor/#example-metrics-from-cadvisor","title":"\ud83d\udcc8 Example Metrics from cAdvisor","text":""},{"location":"2-project/cadvisor/#cpu","title":"CPU","text":"<ul> <li><code>container_cpu_usage_seconds_total</code> \u2192 Total CPU time consumed.</li> <li><code>container_cpu_cfs_throttled_seconds_total</code> \u2192 Time container spent throttled.</li> </ul>"},{"location":"2-project/cadvisor/#memory","title":"Memory","text":"<ul> <li><code>container_memory_usage_bytes</code> \u2192 Total memory usage.</li> <li><code>container_memory_working_set_bytes</code> \u2192 Memory actively used.</li> </ul>"},{"location":"2-project/cadvisor/#network","title":"Network","text":"<ul> <li><code>container_network_receive_bytes_total</code></li> <li><code>container_network_transmit_bytes_total</code></li> </ul>"},{"location":"2-project/cadvisor/#filesystem","title":"Filesystem","text":"<ul> <li><code>container_fs_usage_bytes</code></li> <li><code>container_fs_reads_bytes_total</code></li> </ul>"},{"location":"2-project/cadvisor/#running-cadvisor","title":"\u2699\ufe0f Running cAdvisor","text":""},{"location":"2-project/cadvisor/#docker-example","title":"Docker Example","text":"<pre><code>docker run \\\n  --volume=/:/rootfs:ro \\\n  --volume=/var/run:/var/run:rw \\\n  --volume=/sys:/sys:ro \\\n  --volume=/var/lib/docker/:/var/lib/docker:ro \\\n  --publish=8080:8080 \\\n  --detach=true \\\n  --name=cadvisor \\\n  gcr.io/cadvisor/cadvisor:latest\n</code></pre> <p>\ud83d\udc49 Access metrics at:</p> <ul> <li>UI: <code>http://localhost:8080</code></li> <li>Prometheus metrics: <code>http://localhost:8080/metrics</code></li> </ul>"},{"location":"2-project/cadvisor/#cadvisor-in-kubernetes","title":"\ud83d\udd0e cAdvisor in Kubernetes","text":"<p>In Kubernetes, cAdvisor is built into the kubelet:</p> <ul> <li>Every node\u2019s kubelet runs cAdvisor.</li> <li>Metrics are exposed at <code>:4194/metrics/cadvisor</code>.</li> <li>Prometheus scrapes these endpoints.</li> </ul> <p>\ud83d\udc49 Many Kubernetes setups use kubelet\u2019s cAdvisor integration rather than running cAdvisor as a separate container.</p>"},{"location":"2-project/cadvisor/#key-strengths-of-cadvisor","title":"\ud83d\udd0d Key Strengths of cAdvisor","text":"<ul> <li>Container-native: built specifically for container monitoring.</li> <li>Lightweight: low resource overhead.</li> <li>Rich metrics: CPU, memory, disk, network at per-container level.</li> <li>Easy integration: works out-of-the-box with Prometheus.</li> <li>UI dashboard: basic real-time web UI included.</li> </ul>"},{"location":"2-project/cadvisor/#limitations-watch-outs","title":"\u26a0\ufe0f Limitations &amp; Watch Outs","text":"<ul> <li> <p>Short-term storage only \u2192 cAdvisor itself doesn\u2019t persist data (only in-memory).   \u2192 Must use Prometheus or other TSDB for historical metrics.</p> </li> <li> <p>Scalability \u2192 Standalone cAdvisor isn\u2019t meant for very large clusters.</p> </li> <li> <p>Limited security \u2192 Exposes metrics unauthenticated (protect behind reverse proxy).</p> </li> <li> <p>Deprecation concern \u2192 Standalone cAdvisor development has slowed since metrics are now integrated into Kubernetes kubelet.</p> </li> </ul>"},{"location":"2-project/cadvisor/#example-prometheus-scrape-config-for-cadvisor","title":"\ud83d\udd14 Example Prometheus Scrape Config for cAdvisor","text":"<pre><code>scrape_configs:\n  - job_name: 'cadvisor'\n    static_configs:\n      - targets: ['localhost:8080']\n</code></pre>"},{"location":"2-project/cadvisor/#grafana-dashboards-for-cadvisor","title":"\ud83d\udcca Grafana Dashboards for cAdvisor","text":"<p>Grafana has many pre-built dashboards (via Grafana.com) for cAdvisor metrics:</p> <ul> <li>Container CPU &amp; memory usage</li> <li>Disk &amp; network performance</li> <li>Top N containers by resource consumption</li> <li>Per-pod or per-namespace breakdown</li> </ul> <p>\ud83d\udc49 Example dashboard ID: 893 (Google cAdvisor).</p>"},{"location":"2-project/cadvisor/#alternatives-to-cadvisor","title":"\ud83d\udee0\ufe0f Alternatives to cAdvisor","text":"Tool Focus Notes node_exporter Host-level metrics No per-container visibility kubelet /metrics Node &amp; pod metrics in k8s Already includes cAdvisor functionality Docker stats API Docker container metrics Limited, less Prometheus-friendly Datadog/ELK/others SaaS full observability stacks More features, but paid solutions <p>\ud83d\udc49 In Kubernetes, cAdvisor + kubelet is usually enough.</p>"},{"location":"2-project/cadvisor/#security-best-practices","title":"\ud83d\udee1\ufe0f Security Best Practices","text":"<ul> <li>\u274c Don\u2019t expose cAdvisor directly to the internet.</li> <li>\u2705 Run behind a reverse proxy (Nginx, Traefik).</li> <li>\u2705 Scrape metrics only from trusted networks.</li> <li>\u2705 Use Kubernetes RBAC with kubelet metrics proxying.</li> </ul>"},{"location":"2-project/cadvisor/#cadvisor-cheat-sheet","title":"\ud83e\uddfe cAdvisor Cheat Sheet","text":""},{"location":"2-project/cadvisor/#core-concepts","title":"\u2705 Core Concepts","text":"Term Meaning cAdvisor Container metrics daemon (by Google) Source Linux kernel cgroups + container runtime Metrics CPU, memory, disk, network per container Endpoint <code>/metrics</code> (Prometheus format)"},{"location":"2-project/cadvisor/#example-promql","title":"\ud83d\udcca Example PromQL","text":"<pre><code>rate(container_cpu_usage_seconds_total[1m])   # CPU usage per second\ncontainer_memory_usage_bytes                  # Current memory usage\ncontainer_network_receive_bytes_total         # Network RX bytes\n</code></pre>"},{"location":"2-project/cadvisor/#final-takeaway","title":"\ud83c\udfaf Final Takeaway","text":"<p>cAdvisor is:</p> <ul> <li>Essential for per-container resource monitoring.</li> <li>Lightweight and easy to deploy.</li> <li>Integrated into Kubernetes via kubelet.</li> <li>Best used with Prometheus + Grafana for long-term monitoring.</li> </ul> <p>\ud83d\udc49 Think of cAdvisor as the container-level metrics engine that feeds Prometheus, while node_exporter gives you host-level metrics.</p>"},{"location":"2-project/grafana/","title":"Grafana","text":""},{"location":"2-project/grafana/#what-is-grafana","title":"\ud83d\udcca What is Grafana?","text":"<p>Grafana is an open-source observability and visualization platform. It lets you query, visualize, alert, and explore metrics, logs, and traces from multiple data sources.</p> <p>Originally created by Torkel \u00d6degaard, Grafana has grown into a CNCF incubating project and is now the de facto dashboarding tool in cloud-native monitoring stacks.</p> <p>\ud83d\udc49 If Prometheus is the \u201cbrain\u201d of monitoring (data collection &amp; querying), Grafana is the eyes (dashboards &amp; visualizations).</p>"},{"location":"2-project/grafana/#why-do-we-need-grafana","title":"\ud83e\uddd0 Why Do We Need Grafana?","text":"<p>Modern systems generate huge amounts of telemetry data:</p> <ul> <li>Metrics (from Prometheus, InfluxDB, Graphite, etc.)</li> <li>Logs (from Loki, Elasticsearch, Splunk, etc.)</li> <li>Traces (from Jaeger, Tempo, Zipkin, etc.)</li> </ul> <p>Without visualization, raw metrics are hard to interpret. Grafana solves this by:</p> <ul> <li>Turning metrics into interactive dashboards</li> <li>Providing alerting when thresholds are crossed</li> <li>Enabling multi-source observability (metrics + logs + traces in one UI)</li> </ul> <p>\ud83d\udc49 Grafana = single pane of glass for observability.</p>"},{"location":"2-project/grafana/#how-grafana-works","title":"\ud83d\udd27 How Grafana Works","text":"<p>Grafana itself does not collect data. Instead, it:</p> <ol> <li>Connects to data sources (Prometheus, Loki, Elasticsearch, etc.)</li> <li>Executes queries against them</li> <li>Renders results in panels (graphs, gauges, tables, heatmaps, etc.)</li> <li>Organizes panels into dashboards</li> <li>Provides alerting &amp; notifications based on panel queries</li> </ol>"},{"location":"2-project/grafana/#architecture-overview","title":"\ud83d\udd17 Architecture Overview","text":"<pre><code>+------------------+\n| Data Sources     |   (Prometheus, Loki, Tempo, etc.)\n+---------+--------+\n          |\n          v\n+---------+---------+\n|  Grafana Server   |\n|  - Query engine   |\n|  - Panels         |\n|  - Alerting       |\n+---------+---------+\n          |\n   +------+------+\n   | Dashboards |\n   +------+------+\n          |\n      End Users\n</code></pre>"},{"location":"2-project/grafana/#data-flow-from-metrics-grafana-user","title":"\ud83d\udd04 Data Flow: From Metrics \u2192 Grafana \u2192 User","text":"<pre><code>sequenceDiagram\n    participant DS as Data Source (Prometheus, Loki, etc.)\n    participant G as Grafana\n    participant User as User (SRE/DevOps)\n\n    User-&gt;&gt;G: Request dashboard\n    G-&gt;&gt;DS: Query metrics/logs/traces\n    DS--&gt;&gt;G: Return results\n    G--&gt;&gt;User: Render panels\n    G-&gt;&gt;User: Send alerts (if configured)</code></pre>"},{"location":"2-project/grafana/#example-grafana-panels","title":"\ud83d\udcca Example Grafana Panels","text":"<p>Grafana supports many visualization types:</p> <ul> <li>Time series graph \u2192 CPU usage over time</li> <li>Gauge / SingleStat \u2192 current memory usage</li> <li>Heatmap \u2192 latency distribution</li> <li>Table \u2192 list of failing pods</li> <li>Pie chart \u2192 % of requests per region</li> </ul> <p>\ud83d\udc49 Panels can be grouped into dashboards (e.g., \u201cKubernetes Cluster Health\u201d).</p>"},{"location":"2-project/grafana/#common-data-sources","title":"\ud83d\udee0 Common Data Sources","text":"<p>Grafana supports dozens of backends. Most common:</p> Type Example Purpose Metrics Prometheus, InfluxDB, Graphite Time-series metrics Logs Loki, Elasticsearch, Splunk Centralized logging Traces Tempo, Jaeger, Zipkin Distributed tracing Databases MySQL, PostgreSQL Custom queries Cloud AWS CloudWatch, GCP Monitoring, Azure Monitor Cloud-native monitoring <p>\ud83d\udc49 Grafana turns it into a multi-source observability platform.</p>"},{"location":"2-project/grafana/#alerting-in-grafana","title":"\ud83d\udd14 Alerting in Grafana","text":"<p>Grafana provides a unified alerting system (since v8):</p> <ul> <li>Create alerts directly from panels.</li> <li>Alerts are evaluated on the Grafana server.</li> <li> <p>Notifications are sent via channels:</p> </li> <li> <p>Slack</p> </li> <li>Email</li> <li>PagerDuty</li> <li>Microsoft Teams</li> <li>Webhooks</li> </ul>"},{"location":"2-project/grafana/#example-alert-flow","title":"Example Alert Flow","text":"<ol> <li>Define a threshold (e.g., CPU usage &gt; 80%).</li> <li>Grafana runs the query periodically.</li> <li>If condition matches, an alert fires.</li> <li>Notification goes to configured channel.</li> </ol>"},{"location":"2-project/grafana/#installing-grafana","title":"\u2699\ufe0f Installing Grafana","text":""},{"location":"2-project/grafana/#docker","title":"Docker","text":"<pre><code>docker run -d -p 3000:3000 grafana/grafana\n</code></pre> <ul> <li>UI: <code>http://localhost:3000</code></li> <li>Default credentials: <code>admin/admin</code></li> </ul>"},{"location":"2-project/grafana/#kubernetes-helm","title":"Kubernetes (Helm)","text":"<pre><code>helm repo add grafana https://grafana.github.io/helm-charts\nhelm install grafana grafana/grafana\n</code></pre>"},{"location":"2-project/grafana/#security-best-practices","title":"\ud83d\udee1\ufe0f Security Best Practices","text":"<ul> <li>\u2705 Always set admin password (default is insecure).</li> <li>\u2705 Enable TLS if exposed publicly.</li> <li>\u2705 Use OAuth/SAML/LDAP for authentication.</li> <li>\u2705 Use folders &amp; permissions to restrict dashboard access.</li> <li>\u2705 Enable audit logs for compliance.</li> </ul>"},{"location":"2-project/grafana/#key-strengths-of-grafana","title":"\ud83d\udd0d Key Strengths of Grafana","text":"<ul> <li>\ud83c\udf10 Multi-data-source (metrics, logs, traces, SQL, cloud).</li> <li>\ud83c\udfa8 Rich visualizations (100+ panel types, plugins).</li> <li>\ud83d\udce6 Pre-built dashboards (Grafana.com library).</li> <li>\u26a1 Fast querying &amp; exploration (great with Prometheus).</li> <li>\ud83d\udce2 Unified alerting with many integrations.</li> <li>\ud83d\udd0c Extensible (plugins for panels, datasources, apps).</li> </ul>"},{"location":"2-project/grafana/#limitations-watch-outs","title":"\u26a0\ufe0f Limitations &amp; Watch Outs","text":"<ul> <li>\u274c No storage \u2192 relies on external data sources.</li> <li>\u274c Query-heavy dashboards \u2192 can overload Prometheus/DB.</li> <li>\u274c High availability setup requires external DB (MySQL/Postgres).</li> <li>\u274c User management is limited in OSS (Grafana Enterprise adds RBAC, reporting).</li> </ul>"},{"location":"2-project/grafana/#grafana-in-the-observability-stack","title":"\ud83d\udce6 Grafana in the Observability Stack","text":"<pre><code>flowchart TD\n\n    subgraph Metrics\n        P[Prometheus]\n        N[node_exporter]\n        C[cAdvisor]\n    end\n\n    subgraph Logs\n        L[Loki]\n    end\n\n    subgraph Traces\n        T[Tempo]\n    end\n\n    subgraph Grafana[\"Grafana Dashboards\"]\n        G[\"Dashboards + Alerts\"]\n    end\n\n    P --&gt; G\n    L --&gt; G\n    T --&gt; G</code></pre> <p>\ud83d\udc49 Grafana = central observability frontend for metrics, logs, and traces.</p>"},{"location":"2-project/grafana/#grafana-cheat-sheet","title":"\ud83e\uddfe Grafana Cheat Sheet","text":""},{"location":"2-project/grafana/#core-concepts","title":"\u2705 Core Concepts","text":"Term Meaning Data source External system providing data (Prometheus, Loki, etc.) Panel Single visualization (graph, table, etc.) Dashboard Collection of panels Alert Rule based on a query, triggers notification Organization Multi-tenant separation in Grafana Folder Logical grouping of dashboards"},{"location":"2-project/grafana/#common-use-cases","title":"\ud83d\udcca Common Use Cases","text":"<ul> <li>System monitoring (CPU, memory, disk usage).</li> <li>Kubernetes monitoring (pods, nodes, namespaces).</li> <li>Business metrics (orders per minute, revenue trends).</li> <li>Application performance monitoring (APM).</li> <li>Log exploration (with Loki/Elasticsearch).</li> </ul>"},{"location":"2-project/grafana/#final-takeaway","title":"\ud83c\udfaf Final Takeaway","text":"<p>Grafana is:</p> <ul> <li>The visualization + alerting layer of modern monitoring stacks.</li> <li>Datasource-agnostic (works with metrics, logs, traces, SQL).</li> <li>Essential for Kubernetes, microservices, and cloud-native setups.</li> </ul> <p>\ud83d\udc49 Think of Grafana as the dashboard and control room where DevOps, SREs, and engineers get their insights.</p>"},{"location":"2-project/prometheus/","title":"\ud83d\udcca What is Prometheus?","text":"<p>Prometheus is an open-source monitoring and alerting toolkit designed for time-series data (metrics with timestamps). It was created at SoundCloud and is now a CNCF graduated project (same foundation as Kubernetes).  </p> <p>Prometheus has become the de facto standard for monitoring in cloud-native environments, especially with Kubernetes, due to its scalability, flexibility, and ecosystem.</p>"},{"location":"2-project/prometheus/#why-do-we-need-monitoring","title":"\ud83e\uddd0 Why Do We Need Monitoring?","text":"<p>Modern systems are:</p> <ul> <li>Distributed (many services, microservices, containers).</li> <li>Dynamic (instances scale up and down).</li> <li>Complex (multiple dependencies, networks, storage).</li> </ul> <p>Without monitoring, failures remain invisible until users complain.  </p> <p>Monitoring answers:</p> <ul> <li>Is my service up?</li> <li>How much traffic am I serving?</li> <li>Are we running into errors, bottlenecks, or slowdowns?</li> <li>When should we scale?</li> </ul> <p>Monitoring data comes in three main forms (the \u201cthree pillars of observability\u201d):</p> <ol> <li>Logs \u2192 Event-based, detailed messages.  </li> <li>Metrics \u2192 Numeric measurements over time (cheap, efficient).  </li> <li>Traces \u2192 End-to-end request tracking.  </li> </ol> <p>\ud83d\udc49 Prometheus focuses on metrics.</p>"},{"location":"2-project/prometheus/#time-series-basics","title":"\ud83d\udd52 Time-Series Basics","text":"<p>A time series is a sequence of values recorded at successive points in time. Example:  </p> Time Metric Value 10:00 CPU usage 30% 10:01 CPU usage 32% 10:02 CPU usage 31% <p>Each metric in Prometheus is:</p> <ul> <li>Metric name \u2192 <code>http_requests_total</code> </li> <li>Labels (key-value pairs for context) \u2192 <code>{method=\"GET\", status=\"200\"}</code> </li> <li>Timestamp + value </li> </ul> <p>This allows very powerful queries like: \ud83d\udc49 \u201cHow many <code>GET</code> requests per second returned a <code>500</code> error in the last 5 minutes?\u201d</p>"},{"location":"2-project/prometheus/#video-introduction","title":"\ud83c\udfa5 Video Introduction","text":""},{"location":"2-project/prometheus/#how-prometheus-works","title":"\ud83d\udd27 How Prometheus Works","text":"<p>Prometheus is built around a pull-based model:</p> <ol> <li>Targets expose metrics via HTTP (usually at <code>/metrics</code>).</li> <li>Prometheus scrapes metrics at regular intervals.</li> <li>Data is stored in its own time-series database (TSDB).</li> <li>Metrics can be queried using PromQL (Prometheus Query Language).</li> <li>Alerting rules can trigger alerts via Alertmanager.</li> <li>For short-lived jobs, metrics can be pushed via Pushgateway.</li> </ol>"},{"location":"2-project/prometheus/#architecture-overview","title":"\ud83d\udd17 Architecture Overview","text":"<pre><code>          +-------------------+\n          |    Applications   |\n          |  Export metrics   |\n          +---------+---------+\n                    |\n                    v\n          +---------+---------+\n          |  Exporters        |   (e.g. node_exporter, redis_exporter)\n          +---------+---------+\n                    |\n                    v\n          +---------+---------+\n          | Prometheus Server |   (scrapes, stores, queries data)\n          +---------+---------+\n               |          |\n         (alerts)    (queries)\n               |          |\n          +----v----+ +---v---+\n          |Alertmgr | | Grafana|\n          +---------+ +--------+\n</code></pre>"},{"location":"2-project/prometheus/#metric-flow-from-app-prometheus-user","title":"\ud83d\udd04 Metric Flow: From App \u2192 Prometheus \u2192 User","text":"<p>Below is a user flow diagram that explains how a single metric travels through the system.</p> <pre><code>sequenceDiagram\n    participant App as Application\n    participant Exp as Exporter (/metrics)\n    participant Prom as Prometheus Server\n    participant Graf as Grafana\n    participant AM as Alertmanager\n    participant User as User / SRE\n\n    App-&gt;&gt;Exp: Expose metrics (HTTP /metrics)\n    Prom-&gt;&gt;Exp: Scrape metrics (pull)\n    Prom-&gt;&gt;Prom: Store in TSDB (time-series DB)\n    User-&gt;&gt;Graf: Request dashboard\n    Graf-&gt;&gt;Prom: Query via PromQL\n    Prom--&gt;&gt;Graf: Return metrics\n    Graf--&gt;&gt;User: Display visualization\n\n    Prom-&gt;&gt;Prom: Evaluate alert rules\n    Prom-&gt;&gt;AM: Send alert\n    AM--&gt;&gt;User: Notify (Slack/Email/PagerDuty)</code></pre>"},{"location":"2-project/prometheus/#explanation-of-the-flow","title":"\ud83d\udd0e Explanation of the Flow","text":"<ol> <li>App \u2192 exposes metrics (or uses an exporter).  </li> <li>Prometheus \u2192 regularly scrapes metrics via HTTP pull.  </li> <li>Prometheus TSDB \u2192 stores the metrics with timestamps.  </li> <li>Grafana \u2192 users query metrics with PromQL and visualize them.  </li> <li>Alertmanager \u2192 gets triggered if rules match (CPU &gt; 90%, target down, etc.).  </li> <li>User (SRE/DevOps) \u2192 gets notified and investigates.  </li> </ol>"},{"location":"2-project/prometheus/#key-strengths-of-prometheus","title":"\ud83d\udd0d Key Strengths of Prometheus","text":"<ul> <li>Standalone: no external database required.</li> <li>PromQL: powerful and flexible query language for metrics.</li> <li>Kubernetes-native: integrates seamlessly with service discovery.</li> <li>Ecosystem: works with Grafana, Alertmanager, Pushgateway, Thanos, Cortex.</li> <li>Scalable: handles thousands of metrics and targets efficiently.</li> </ul>"},{"location":"2-project/prometheus/#limitations-watch-outs","title":"\u26a0\ufe0f Limitations &amp; Watch Outs","text":"<ul> <li> <p>Not ideal for long-term storage \u2192 data retention is limited (usually weeks).   \u2192 Solution: use Thanos, Cortex, or Mimir for long-term.</p> </li> <li> <p>High cardinality \u2192 too many unique label combinations can overwhelm memory.   \u2192 Example: <code>user_id</code> as a label \u2192 \u274c (millions of unique values).</p> </li> <li> <p>Pull model challenges \u2192 doesn\u2019t fit well with:</p> </li> <li> <p>Short-lived jobs (use Pushgateway).</p> </li> <li> <p>Firewalled environments.</p> </li> <li> <p>No built-in dashboards \u2192 always paired with Grafana.</p> </li> </ul>"},{"location":"2-project/prometheus/#promql-the-query-language","title":"\ud83d\udd0d PromQL \u2014 The Query Language","text":"<p>Prometheus comes with PromQL (Prometheus Query Language), which lets you slice, dice, and aggregate metrics. Think of it as SQL for time-series data.</p>"},{"location":"2-project/prometheus/#selectors","title":"\ud83d\udcca Selectors","text":"<pre><code>http_requests_total\n</code></pre> <p>\u27a1\ufe0f Selects all values of <code>http_requests_total</code>.</p> <pre><code>http_requests_total{job=\"api\"}\n</code></pre> <p>\u27a1\ufe0f Selects only metrics where the label <code>job=\"api\"</code>.</p> <pre><code>up == 0\n</code></pre> <p>\u27a1\ufe0f Shows targets that are down.</p>"},{"location":"2-project/prometheus/#aggregations","title":"\ud83d\udd22 Aggregations","text":"<pre><code>sum(http_requests_total)\n</code></pre> <p>\u27a1\ufe0f Total across all series.</p> <pre><code>avg(http_requests_total)\nmax(http_requests_total)\nmin(http_requests_total)\ncount(http_requests_total)\n</code></pre> <p>With labels:</p> <pre><code>sum by (job)(http_requests_total)   # Sum per job\navg by (instance)(up)               # Average per instance\n</code></pre>"},{"location":"2-project/prometheus/#rate-increase","title":"\ud83e\uddee Rate &amp; Increase","text":"<p>Counters (monotonically increasing metrics) should not be summed directly; instead use rates:</p> <pre><code>rate(http_requests_total[1m])\n</code></pre> <p>\u27a1\ufe0f Average per-second increase over the last 1 minute.</p> <pre><code>increase(http_requests_total[5m])\n</code></pre> <p>\u27a1\ufe0f Total increase in the last 5 minutes.</p>"},{"location":"2-project/prometheus/#common-alert-conditions","title":"\ud83d\udca5 Common Alert Conditions","text":"<pre><code>rate(http_requests_total[5m]) &gt; 100\n</code></pre> <p>\u27a1\ufe0f High request rate.</p> <pre><code>node_memory_Active_bytes / node_memory_MemTotal_bytes &gt; 0.9\n</code></pre> <p>\u27a1\ufe0f Memory usage above 90%.</p> <pre><code>up == 0\n</code></pre> <p>\u27a1\ufe0f Target is down.</p>"},{"location":"2-project/prometheus/#alerting-with-prometheus-alertmanager","title":"\ud83d\udd14 Alerting with Prometheus + Alertmanager","text":"<p>Prometheus can define alert rules. When triggered, alerts are sent to Alertmanager, which handles:</p> <ul> <li>Routing (who should be notified?).</li> <li>Silencing (ignore alerts during maintenance).</li> <li>Grouping (combine related alerts).</li> <li>Delivery (email, Slack, PagerDuty, etc.).</li> </ul>"},{"location":"2-project/prometheus/#example-alert-rule-yaml","title":"Example Alert Rule (YAML)","text":"<pre><code>groups:\n  - name: example.rules\n    rules:\n      - alert: HighCPUUsage\n        expr: rate(process_cpu_seconds_total[1m]) &gt; 0.85\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High CPU usage on {{ $labels.instance }}\"\n          description: \"CPU &gt; 85% for 2 minutes.\"\n</code></pre>"},{"location":"2-project/prometheus/#metric-types-in-prometheus","title":"\ud83d\udcc8 Metric Types in Prometheus","text":"<p>Prometheus supports four primary metric types:</p> Type Use For Example <code>counter</code> Monotonically increasing values <code>http_requests_total</code> (total requests) <code>gauge</code> Arbitrary values (up &amp; down) <code>memory_usage_bytes</code>, <code>temperature_c</code> <code>histogram</code> Buckets of observations (distribution) Request latency buckets <code>summary</code> Similar to histogram, client-calculated Percentiles of request durations"},{"location":"2-project/prometheus/#common-exporters","title":"\ud83d\udee0 Common Exporters","text":"<p>Prometheus itself doesn\u2019t know about your apps \u2014 exporters bridge the gap. They expose metrics in Prometheus format.</p> Exporter Purpose <code>node_exporter</code> Host/system metrics (CPU, memory, disk) <code>blackbox_exporter</code> Probes HTTP, TCP, DNS endpoints <code>postgres_exporter</code> PostgreSQL database metrics <code>redis_exporter</code> Redis performance metrics <code>nginx_exporter</code> Nginx server stats <code>cadvisor</code> Container runtime (Docker, Kubernetes) <code>kube-state-metrics</code> Kubernetes object states (Pods, Deploys) <p>\ud83d\udc49 Exporters make Prometheus flexible: if it speaks HTTP, you can monitor it.</p>"},{"location":"2-project/prometheus/#prometheus-configuration","title":"\u2699\ufe0f Prometheus Configuration","text":"<p>Prometheus is configured using a YAML file (<code>prometheus.yml</code>). The most important part is <code>scrape_configs</code>, which tells Prometheus what to scrape.</p>"},{"location":"2-project/prometheus/#example-scraping-a-django-app","title":"Example: Scraping a Django App","text":"<pre><code>scrape_configs:\n  - job_name: 'django-app'\n    static_configs:\n      - targets: ['localhost:8001']\n</code></pre> <ul> <li><code>job_name</code>: Logical name for the service.</li> <li><code>targets</code>: List of endpoints exposing <code>/metrics</code>.</li> </ul> <p>In Kubernetes, this is usually handled with ServiceMonitor or PodMonitor (via the Prometheus Operator).</p>"},{"location":"2-project/prometheus/#security-best-practices","title":"\ud83d\udee1\ufe0f Security Best Practices","text":"<p>Prometheus itself has minimal security features \u2014 you must secure it.</p> <ul> <li>\u274c Don\u2019t expose Prometheus directly to the public internet.</li> <li>\u2705 Put it behind a reverse proxy (Nginx/Traefik) with auth.</li> <li>\u2705 Enable TLS if exposing metrics across networks.</li> <li>\u2705 Sanitize metrics: avoid sensitive labels (<code>user_id</code>, <code>token</code>, etc.).</li> <li>\u2705 Monitor Prometheus itself: it exposes <code>/metrics</code> too.</li> </ul>"},{"location":"2-project/prometheus/#scaling-long-term-storage","title":"\ud83d\udce6 Scaling &amp; Long-Term Storage","text":"<p>Prometheus by itself is single-node and best for short to medium retention. For enterprise or multi-cluster setups:</p> <ul> <li>Thanos \u2192 Adds object storage (S3, GCS) for long-term retention + global query view.</li> <li>Cortex / Mimir \u2192 Horizontal scaling of Prometheus for multi-tenant setups.</li> <li>Federation \u2192 One Prometheus scrapes another to aggregate metrics.</li> </ul> <p>\ud83d\udc49 Rule of thumb:</p> <ul> <li>Small teams \u2192 Single Prometheus.</li> <li>Medium-large \u2192 Prometheus + Thanos.</li> <li>Very large / SaaS \u2192 Cortex/Mimir.</li> </ul>"},{"location":"2-project/prometheus/#best-practical-approach","title":"\ud83d\udd00 Best Practical Approach","text":"<ul> <li>Use the Prometheus + Grafana + Alertmanager stack.</li> <li>For long-term, add Thanos or Cortex.</li> <li>For high-cardinality metrics, aggregate early or pre-process with OpenTelemetry.</li> <li>Always monitor Prometheus itself (<code>up</code>, <code>scrape_duration_seconds</code>, etc.).</li> </ul>"},{"location":"2-project/prometheus/#comparison-with-alternatives","title":"\ud83d\udd0d Comparison with Alternatives","text":"Tool Type Strengths Weaknesses Prometheus Open-source Powerful, CNCF standard, Kubernetes-native Not built for long-term storage InfluxDB Time-series DB SQL-like query (Flux), good dashboards Less Kubernetes-native Datadog SaaS Turnkey, integrations, great UI Expensive, vendor lock-in New Relic SaaS APM Tracing + metrics + logs in one Cost, complexity Graphite Legacy OSS Simple, widely used historically Weak ecosystem, aging"},{"location":"2-project/prometheus/#prometheus-cheat-sheet","title":"\ud83e\uddfe Prometheus Cheat Sheet","text":""},{"location":"2-project/prometheus/#core-concepts","title":"\u2705 Core Concepts","text":"Term Meaning Target App exposing metrics at <code>/metrics</code> Exporter Adapter exposing metrics in Prometheus format Scrape Prometheus pulling metrics from a target Time Series Metric name + labels + timestamp + value Label Key-value metadata (e.g. <code>job=\"api\"</code>, <code>env=\"prod\"</code>)"},{"location":"2-project/prometheus/#promql-cheat-sheet","title":"\ud83d\udd0d PromQL Cheat Sheet","text":"<p>Selectors</p> <pre><code>http_requests_total\nhttp_requests_total{job=\"api\"}\nup == 0\n</code></pre> <p>Aggregations</p> <pre><code>sum(http_requests_total)\nsum by (job)(http_requests_total)\n</code></pre> <p>Rates</p> <pre><code>rate(http_requests_total[1m])\nincrease(http_requests_total[5m])\n</code></pre> <p>Alert Conditions</p> <pre><code>up == 0\nrate(http_requests_total[5m]) &gt; 100\n</code></pre>"},{"location":"2-project/prometheus/#alerting-rule-yaml","title":"\ud83d\udd14 Alerting Rule (YAML)","text":"<pre><code>groups:\n  - name: example.rules\n    rules:\n      - alert: HighMemoryUsage\n        expr: node_memory_Active_bytes / node_memory_MemTotal_bytes &gt; 0.9\n        for: 2m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High memory usage on {{ $labels.instance }}\"\n          description: \"Above 90% memory for 2 minutes.\"\n</code></pre>"},{"location":"2-project/prometheus/#exporters-you-should-know","title":"\ud83d\udcc8 Exporters You Should Know","text":"<ul> <li><code>node_exporter</code> \u2192 System metrics.</li> <li><code>blackbox_exporter</code> \u2192 Probes (HTTP, TCP, DNS).</li> <li><code>postgres_exporter</code> \u2192 Database stats.</li> <li><code>redis_exporter</code> \u2192 Redis performance.</li> <li><code>cadvisor</code> \u2192 Container metrics.</li> <li><code>kube-state-metrics</code> \u2192 Kubernetes object state.</li> </ul>"},{"location":"2-project/prometheus/#security-tips","title":"\ud83d\udee1\ufe0f Security Tips","text":"<ul> <li>Don\u2019t scrape metrics endpoints over the internet.</li> <li>Use auth + TLS where possible.</li> <li>Avoid exposing sensitive data via labels.</li> </ul>"},{"location":"2-project/prometheus/#tldr-reference-table","title":"\ud83e\uddfe TL;DR Reference Table","text":"Task PromQL/Tool Check if a service is up <code>up{job=\"service\"} == 1</code> Request rate (per second) <code>rate(http_requests_total[1m])</code> Memory usage % <code>node_memory_Active_bytes / node_memory_MemTotal_bytes</code> CPU usage alert rule <code>rate(process_cpu_seconds_total[1m]) &gt; 0.85</code> Aggregate by label <code>sum by (job)(metric_name)</code> Down targets <code>up == 0</code> Visualisation Grafana"},{"location":"2-project/prometheus/#prometheus-thanos-architecture","title":"\ud83c\udfd7\ufe0f Prometheus + Thanos Architecture","text":"<p>It\u2019s best to first show core Prometheus architecture, then later show the scaled Prometheus + Thanos setup.</p>"},{"location":"2-project/prometheus/#core-prometheus-architecture","title":"\ud83c\udfd7\ufe0f Core Prometheus Architecture","text":"<pre><code>flowchart TD\n\n    subgraph Apps[Applications &amp; Services]\n        A1[App 1] --&gt;|/metrics| E1[Exporter]\n        A2[App 2] --&gt;|/metrics| E2[Exporter]\n        A3[Database] --&gt;|/metrics| E3[Exporter]\n    end\n\n    subgraph PrometheusCore[Prometheus Server]\n        P[Prometheus]\n    end\n\n    E1 --&gt; P\n    E2 --&gt; P\n    E3 --&gt; P\n\n    P --&gt;|Queries| Grafana[(Grafana Dashboards)]\n    P --&gt;|Alerts| Alertmanager[(Alertmanager)]</code></pre>"},{"location":"2-project/prometheus/#explanation-of-the-core-diagram","title":"\ud83d\udd0e Explanation of the Core Diagram","text":"<ul> <li>Apps/Databases \u2192 expose metrics via exporters.  </li> <li>Prometheus server \u2192 scrapes data, stores it in its TSDB.  </li> <li>Grafana \u2192 queries Prometheus for dashboards.  </li> <li>Alertmanager \u2192 receives alerts when rules trigger.  </li> </ul> <p>This shows the essential workflow without the complexity of scaling.  </p> <p>The following visual diagram shows how Prometheus scales with Thanos (for long-term storage and HA). <pre><code>flowchart TD\n\n    subgraph AppLayer[\"Applications &amp; Services\"]\n        A1[\"App 1\"] --&gt;|/metrics| E1[Exporter]\n        A2[\"App 2\"] --&gt;|/metrics| E2[Exporter]\n        A3[\"Database\"] --&gt;|/metrics| E3[Exporter]\n    end\n\n    subgraph PrometheusCluster[\"Prometheus Servers\"]\n        P1[\"Prometheus #1\"]\n        P2[\"Prometheus #2\"]\n    end\n\n    E1 --&gt; P1\n    E2 --&gt; P1\n    E3 --&gt; P2\n\n    subgraph Thanos[\"Thanos Components\"]\n        Q[\"Thanos Querier\"]\n        S[\"Thanos Sidecar\"]\n        G[\"Thanos Store Gateway\"]\n        C[\"Object Storage (S3/GCS/Azure)\"]\n    end\n\n    P1 --&gt; S\n    P2 --&gt; S\n    S --&gt; C\n    C --&gt; G\n    G --&gt; Q\n    P1 --&gt; Q\n    P2 --&gt; Q\n\n    Q --&gt; Grafana[\"Grafana Dashboards\"]\n    Q --&gt; Alertmanager[\"Alertmanager\"]</code></pre></p>"},{"location":"2-project/prometheus/#explanation-of-the-diagram","title":"\ud83d\udd0e Explanation of the Diagram","text":"<ul> <li>Applications/Exporters \u2192 expose metrics at <code>/metrics</code>.  </li> <li>Prometheus Servers \u2192 scrape and store metrics locally.  </li> <li>Thanos Sidecar \u2192 connects Prometheus to long-term storage.  </li> <li>Object Storage (S3/GCS) \u2192 stores historical metrics.  </li> <li>Thanos Store Gateway + Querier \u2192 allow querying all Prometheus + historical data.  </li> <li>Grafana &amp; Alertmanager \u2192 visualization + alerting, now with global view.  </li> </ul>"},{"location":"2-project/prometheus/#final-takeaway","title":"\ud83c\udfaf Final Takeaway","text":"<p>Prometheus is:</p> <ul> <li>Simple to start with.</li> <li>Powerful with PromQL.</li> <li>Scalable with Thanos/Cortex.</li> <li>Best-in-class for cloud-native monitoring.</li> </ul> <p>\ud83d\udc49 If you\u2019re running Kubernetes or microservices, Prometheus should be your first monitoring tool of choice.</p>"},{"location":"2-project/setup/","title":"Setting things up","text":"<p>Let's dive into setting this stack up, step by step.</p> <p>Our effective folder structure is as below:</p> <pre><code>.\n\u251c\u2500\u2500 prometheus/ # prometheus config files\n\u251c\u2500\u2500 grafana/ # grafana config files\n\u251c\u2500\u2500 docker-compose.yaml # spins the prometheus and grafana containers\n</code></pre> <p>All files are fully commented.</p>"},{"location":"2-project/setup/#docker-swarm-setup","title":"Docker Swarm setup","text":"<p>We first setup our swarm. Below is a reminder of what our ideal swarm looks like:</p> <p></p> <p>We won't have this for now as we will be testing locally.</p>"},{"location":"2-project/setup/#monitoring-your-own-app","title":"Monitoring your own app","text":"<p>We\u2019ve already got the infrastructure monitoring stack:</p> <ul> <li>cAdvisor \u2192 monitors Docker containers (CPU, RAM, FS, network).</li> <li>Node Exporter \u2192 monitors host machine metrics.</li> <li>Prometheus \u2192 scrapes metrics.</li> <li>Grafana \u2192 visualizes everything.</li> </ul> <p>Now the question is: \ud83d\udc49 How do we monitor your app running in Docker?</p>"},{"location":"2-project/setup/#3-ways-to-monitor-your-app-in-this-stack","title":"\ud83d\udee0 3 ways to monitor your app in this stack","text":""},{"location":"2-project/setup/#1-basic-container-level-monitoring-already-covered","title":"1. Basic container-level monitoring (already covered)","text":"<p>If your app is just a Docker container (say Nginx, MySQL, etc.), then cAdvisor automatically collects:</p> <ul> <li>CPU usage</li> <li>Memory usage</li> <li>Network traffic</li> <li>Filesystem usage</li> </ul> <p>\u2705 You get this \u201cfor free\u201d already \u2014 no config changes needed.</p>"},{"location":"2-project/setup/#2-app-specific-exporters-most-common","title":"2. App-specific exporters (most common)","text":"<p>Some apps expose their own Prometheus metrics, or you run an \u201cexporter\u201d alongside them:</p> <ul> <li>Nginx \u2192 nginx-prometheus-exporter</li> <li>Postgres \u2192 postgres_exporter</li> <li>MySQL \u2192 mysqld_exporter</li> <li>Redis \u2192 redis_exporter</li> </ul> <p>Example: monitoring an Nginx container</p> <pre><code>services:\n  nginx:\n    image: nginx:latest\n    ports:\n      - \"8081:80\"\n\n  nginx-exporter:\n    image: nginx/nginx-prometheus-exporter:0.11.0\n    command: -nginx.scrape-uri=http://nginx:80/stub_status\n    ports:\n      - \"9113:9113\"\n</code></pre> <p>Then in your <code>prometheus.yaml</code> add:</p> <pre><code>  - job_name: 'nginx'\n    static_configs:\n      - targets: ['nginx-exporter:9113']\n</code></pre>"},{"location":"2-project/setup/#3-custom-metrics-if-you-wrote-the-app","title":"3. Custom metrics (if you wrote the app)","text":"<p>If you\u2019re coding your own app, you can instrument it with Open Telemetry or a Prometheus client library:</p> <ul> <li>Go \u2192 prometheus/client_golang</li> <li>Python \u2192 prometheus_client</li> <li>Node.js \u2192 prom-client</li> </ul> <p>Then your app exposes <code>/metrics</code>, which Prometheus scrapes.</p> <p>Example (Python Flask app):</p> <pre><code>from flask import Flask\nfrom prometheus_client import Counter, generate_latest\n\napp = Flask(__name__)\nrequests_total = Counter('app_requests_total', 'Total requests')\n\n@app.route('/')\ndef hello():\n    requests_total.inc()\n    return \"Hello, world!\"\n\n@app.route('/metrics')\ndef metrics():\n    return generate_latest(), 200, {'Content-Type': 'text/plain'}\n</code></pre> <p>Run it in Docker, then Prometheus scrapes <code>http://myapp:5000/metrics</code>.</p>"},{"location":"2-project/setup/#summary","title":"\ud83d\udccc Summary","text":"<ul> <li>\u2705 If you just want resource monitoring \u2192 cAdvisor + Node Exporter already do it.</li> <li>\u2705 If you want application metrics \u2192 add exporters (Nginx, DB, etc.) or instrument your own app.</li> <li>\u2705 Prometheus scrapes those metrics, and Grafana dashboards visualize them.</li> </ul>"},{"location":"2-project/setup/#what-opentelemetry-gives-you","title":"\ud83d\udd0e What OpenTelemetry gives you","text":"<ul> <li>Instrumentation libraries for most languages (Python, Go, Java, Node.js, .NET, etc.).</li> <li>Collects application metrics, traces, and optionally logs.</li> <li> <p>You run an OpenTelemetry Collector (agent) that receives this telemetry and forwards it to backends like:</p> </li> <li> <p>Prometheus (metrics)</p> </li> <li>Jaeger/Tempo (traces)</li> <li>Loki/ELK (logs)</li> <li>Grafana/OTLP-compatible backends</li> </ul>"},{"location":"2-project/setup/#how-it-works-in-your-case","title":"\ud83d\udee0 How it works in your case","text":"<p>Right now you have:</p> <ul> <li>Prometheus + Grafana (metrics visualization)</li> <li>cAdvisor + Node Exporter (infra metrics)</li> </ul> <p>If you want to add OpenTelemetry for your app:</p> <ol> <li>Instrument your app with the OTel SDK for your language.</li> <li>Run an OpenTelemetry Collector container in your stack.</li> <li>Configure it to export metrics to Prometheus (or directly to Grafana if you later switch to Grafana Agent/Cloud).</li> </ol>"},{"location":"2-project/setup/#example-adding-otel-collector","title":"\u26a1 Example: Adding OTel Collector","text":"<p>Extend your <code>docker-compose.yaml</code>:</p> <pre><code>  otel-collector:\n    image: otel/opentelemetry-collector-contrib:0.95.0\n    command: [\"--config=/etc/otel-collector-config.yaml\"]\n    volumes:\n      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml\n    ports:\n      - \"4317:4317\"   # OTLP gRPC\n      - \"4318:4318\"   # OTLP HTTP\n    networks:\n      - monitoring\n</code></pre> <p>Create <code>otel-collector-config.yaml</code>:</p> <pre><code>receivers:\n  otlp:\n    protocols:\n      grpc:\n      http:\n\nexporters:\n  prometheus:\n    endpoint: \"0.0.0.0:9464\"\n\nservice:\n  pipelines:\n    metrics:\n      receivers: [otlp]\n      exporters: [prometheus]\n</code></pre> <p>Now:</p> <ul> <li>Your app sends OTLP data to <code>otel-collector:4317</code></li> <li>Collector exposes a Prometheus endpoint on <code>:9464</code></li> <li>Add this to <code>prometheus.yaml</code>:</li> </ul> <pre><code>- job_name: 'otel-app'\n  static_configs:\n    - targets: ['otel-collector:9464']\n</code></pre>"},{"location":"2-project/setup/#why-otel-is-a-good-idea","title":"\u2705 Why OTel is a good idea","text":"<ul> <li>If you\u2019re learning modern observability, OpenTelemetry is the industry standard.</li> <li>Works with Prometheus/Grafana, but also future-proofs you if you later use Jaeger, Tempo, or commercial backends (Datadog, New Relic, Grafana Cloud, etc.).</li> <li>Lets you monitor custom app metrics + traces, not just container resource usage.</li> </ul>"},{"location":"2-project/setup/#networks","title":"\ud83d\udd0e Networks","text":"<ul> <li>In Docker, containers can only talk to each other if they share a network.</li> <li>You already defined a custom network:</li> </ul> <p><pre><code>networks:\n  monitoring:\n</code></pre> * Any service you add with:</p> <pre><code>networks:\n  - monitoring\n</code></pre> <p>will be discoverable by name (DNS resolution inside the network).</p> <p>\ud83d\udc49 Example: Prometheus can scrape <code>cadvisor:8080</code> or <code>otel-collector:9464</code> because they\u2019re all on <code>monitoring</code>.</p>"},{"location":"2-project/setup/#example-adding-an-app-to-your-stack","title":"\ud83d\udee0 Example: Adding an app to your stack","text":"<p>Say you want to run a Python app that exposes metrics:</p> <pre><code>  myapp:\n    build: ./myapp      # has a Dockerfile\n    ports:\n      - \"5000:5000\"     # expose app locally\n    networks:\n      - monitoring\n    environment:\n      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317\n</code></pre> <ul> <li>This app is on the <code>monitoring</code> network.</li> <li>It can send metrics to <code>otel-collector</code>.</li> <li>Prometheus can scrape those metrics via the collector.</li> </ul>"},{"location":"2-project/setup/#do-you-always-need-the-same-compose-file","title":"\ud83d\udd0e Do you always need the same compose file?","text":"<ul> <li>For local dev/lab setups: yes, easiest is one compose file that runs monitoring + apps.</li> <li>In production: you might run monitoring stack separately, and just ensure apps join the same network (or expose metrics on a reachable endpoint).</li> </ul>"},{"location":"2-project/setup/#so-the-rules-are","title":"\u2705 So the rules are:","text":"<ol> <li>Use one compose file for convenience when practicing locally.</li> <li>Make sure your app container joins the same network (<code>monitoring</code>).</li> <li>Add your app/exporter/collector to <code>prometheus.yaml</code> scrape configs.</li> <li>Grafana just sees everything via Prometheus \u2192 dashboards light up.</li> </ol>"},{"location":"2-project/setup/#using-replicas-in-docker-compose-v3","title":"\ud83d\udd0e Using <code>replicas</code> in Docker Compose v3","text":"<p>In your <code>docker-compose.yaml</code>, you can do this:</p> <pre><code>  myapp:\n    image: nginx:alpine\n    deploy:\n      replicas: 3\n    networks:\n      - monitoring\n    ports:\n      - \"8081:80\"\n</code></pre> <ul> <li><code>replicas: 3</code> \u2192 Docker will spin up 3 containers of <code>myapp</code>.</li> <li>Each replica has its own internal hostname/endpoint, but Prometheus can scrape them individually if you tell it to.</li> </ul>"},{"location":"2-project/setup/#how-prometheus-discovers-replicas","title":"\ud83d\udd0e How Prometheus discovers replicas","text":"<p>By default in Compose (non-swarm), replicas are given names like:</p> <ul> <li><code>myapp_1</code></li> <li><code>myapp_2</code></li> <li><code>myapp_3</code></li> </ul> <p>Prometheus cannot auto-discover them unless you use Swarm or Kubernetes. So in <code>prometheus.yaml</code>, you\u2019d need to list them:</p> <pre><code>scrape_configs:\n  - job_name: 'myapp'\n    static_configs:\n      - targets:\n          - 'myapp_1:80'\n          - 'myapp_2:80'\n          - 'myapp_3:80'\n</code></pre>"},{"location":"2-project/setup/#alternative-use-swarm-mode","title":"\ud83d\udd0e Alternative: Use Swarm mode","text":"<p>If you run your stack with Swarm (<code>docker stack deploy</code>), then Prometheus can scrape tasks behind the service name. For example:</p> <pre><code>targets: ['tasks.myapp:80']\n</code></pre> <p>That will automatically resolve to all replicas.</p>"},{"location":"2-project/setup/#practical-takeaway","title":"\u2705 Practical takeaway","text":"<ul> <li>For local Compose testing: yes, you can simulate multiple endpoints with <code>replicas</code>, but you\u2019ll have to list them manually in Prometheus config.</li> <li>For Swarm/Kubernetes: you get service discovery, so Prometheus can scrape all replicas dynamically.</li> </ul>"},{"location":"2-project/setup/#docker-swarm-monitoring","title":"\ud83d\udc33 Docker Swarm + Monitoring","text":"<p>Now let\u2019s go through the Swarm approach carefully, because it\u2019s very relevant for our use-case (monitoring multiple replicas with Prometheus + Grafana). With Swarm, you don\u2019t just run containers, you run services. A service can have replicas, and Swarm automatically handles scaling, networking, and service discovery.</p>"},{"location":"2-project/setup/#1-initialize-swarm","title":"1. Initialize Swarm","text":"<p>On your local machine (or VM):</p> <pre><code>docker swarm init\n</code></pre> <p>This turns your Docker into a Swarm manager. You can add workers with <code>docker swarm join</code>, but for testing, one node is enough.</p>"},{"location":"2-project/setup/#2-compose-file-differences","title":"2. Compose file differences","text":"<p>In Swarm mode, you deploy with:</p> <pre><code>docker stack deploy -c docker-compose.yaml monitoring\n</code></pre> <p>Key points:</p> <ul> <li>Must use <code>version: \"3.x\"</code> in your <code>docker-compose.yaml</code>.</li> <li>The <code>deploy</code> section (including <code>replicas</code>) only works in Swarm.</li> <li>Services run on an overlay network.</li> </ul>"},{"location":"2-project/setup/#3-example-stack-monitoring-app-replicas","title":"3. Example stack (monitoring + app replicas)","text":"<p>Here\u2019s a simplified <code>docker-compose.yaml</code> for Swarm:</p> <pre><code>version: \"3.8\"\n\nnetworks:\n  monitoring:\n    driver: overlay\n\nservices:\n  grafana:\n    image: grafana/grafana:10.0.3\n    ports:\n      - \"3000:3000\"\n    networks:\n      - monitoring\n\n  prometheus:\n    image: prom/prometheus:v2.47.0\n    ports:\n      - \"9090:9090\"\n    configs:\n      - source: prometheus_config\n        target: /etc/prometheus/prometheus.yaml\n    networks:\n      - monitoring\n\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:v0.47.2\n    deploy:\n      mode: global   # one per node\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - /:/rootfs:ro\n      - /var/run:/var/run:ro\n      - /sys:/sys:ro\n      - /var/lib/docker/:/var/lib/docker:ro\n    networks:\n      - monitoring\n\n  node-exporter:\n    image: prom/node-exporter:v1.5.0\n    deploy:\n      mode: global   # one per node\n    ports:\n      - \"9100:9100\"\n    volumes:\n      - /proc:/host/proc:ro\n      - /sys:/host/sys:ro\n    command:\n      - \"--path.procfs=/host/proc\"\n      - \"--path.sysfs=/host/sys\"\n    networks:\n      - monitoring\n\n  myapp:\n    image: nginx:alpine\n    deploy:\n      replicas: 3   # run 3 containers\n    ports:\n      - \"8081:80\"\n    networks:\n      - monitoring\n\nconfigs:\n  prometheus_config:\n    file: ./prometheus.yaml\n</code></pre>"},{"location":"2-project/setup/#4-prometheus-config-for-swarm-discovery","title":"4. Prometheus config for Swarm discovery","text":"<p>Unlike plain Compose, you don\u2019t need to list every replica. You can scrape all tasks of a service:</p> <p><code>prometheus.yaml</code>:</p> <pre><code>global:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'cadvisor'\n    dns_sd_configs:\n      - names: ['tasks.cadvisor']\n        type: A\n        port: 8080\n\n  - job_name: 'node-exporter'\n    dns_sd_configs:\n      - names: ['tasks.node-exporter']\n        type: A\n        port: 9100\n\n  - job_name: 'myapp'\n    dns_sd_configs:\n      - names: ['tasks.myapp']\n        type: A\n        port: 80\n</code></pre> <p>\ud83d\udc49 <code>tasks.&lt;service-name&gt;</code> = DNS entry that resolves to all replicas of that service.</p> <p>So if <code>myapp</code> has 3 replicas, Prometheus scrapes all 3 automatically.</p>"},{"location":"2-project/setup/#5-deploy-the-stack","title":"5. Deploy the stack","text":"<pre><code>docker stack deploy -c docker-compose.yaml monitoring\n</code></pre> <p>Check:</p> <pre><code>docker service ls\ndocker service ps myapp\n</code></pre>"},{"location":"2-project/setup/#6-verify","title":"6. Verify","text":"<ul> <li>Open Grafana \u2192 <code>http://localhost:3000</code></li> <li>Add Prometheus as a datasource \u2192 <code>http://prometheus:9090</code></li> <li>Query <code>up{job=\"myapp\"}</code> \u2192 you should see 3 active targets (1 per replica).</li> <li>Scale easily:</li> </ul> <pre><code>docker service scale myapp=5\n</code></pre> <p>\u2192 Prometheus will now scrape 5 endpoints (automatically, no config change needed).</p>"},{"location":"2-project/setup/#why-swarm-is-better-for-monitoring-replicas","title":"\u2705 Why Swarm is better for monitoring replicas","text":"<ul> <li>Service discovery: Prometheus automatically finds all replicas via DNS (<code>tasks.&lt;service&gt;</code>).</li> <li>Scaling: Add/remove replicas with one command, Prometheus adjusts.</li> <li>Global services: For node-level exporters like cAdvisor and Node Exporter, <code>deploy.mode: global</code> ensures 1 container per node.</li> </ul> <p>\u26a1 Bottom line: In Swarm, Prometheus + Grafana can automatically discover all replicas of your app or exporters. You don\u2019t have to hardcode each replica like in plain Compose. This makes it very close to real-world HA setups.</p>"},{"location":"2-project/setup/#our-setup","title":"Our Setup","text":""},{"location":"2-project/setup/#final-files","title":"Final Files","text":""},{"location":"2-project/setup/#1-docker-composeyaml","title":"1. <code>docker-compose.yaml</code>","text":"<p>Use this Swarm-ready compose (note: <code>container_name</code> is removed because Swarm manages names):</p> <pre><code>version: \"3.8\"\n\nnetworks:\n  monitoring:\n    driver: overlay   # overlay is required for Swarm services\n\nservices:\n  grafana:\n    image: grafana/grafana:10.0.3\n    restart: always\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_PANELS_DISABLE_SANITIZE_HTML=true\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}\n      - GF_USERS_ALLOW_SIGN_UP=false\n    volumes:\n      - ./grafana/grafana-volume:/var/lib/grafana\n    networks:\n      - monitoring\n    deploy:\n      replicas: 1\n\n  prometheus:\n    image: prom/prometheus:v2.47.0\n    restart: always\n    ports:\n      - \"9090:9090\"\n    command:\n      - \"--config.file=/etc/prometheus/prometheus.yaml\"\n      - \"--storage.tsdb.path=/prometheus\"\n      - \"--storage.tsdb.retention.time=7d\"\n      - \"--log.level=warn\"\n    volumes:\n      - ./prometheus:/prometheus\n    configs:\n      - source: prometheus_config\n        target: /etc/prometheus/prometheus.yaml\n    networks:\n      - monitoring\n    deploy:\n      replicas: 1\n\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:v0.47.2\n    command: -logtostderr -docker_only\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - /:/rootfs:ro\n      - /var/run:/var/run:ro\n      - /sys:/sys:ro\n      - /var/lib/docker/:/var/lib/docker:ro\n      - /dev/disk/:/dev/disk:ro\n    networks:\n      - monitoring\n    deploy:\n      mode: global   # one per node\n\n  node-exporter:\n    image: prom/node-exporter:v1.5.0\n    command:\n      - \"--path.sysfs=/host/sys\"\n      - \"--path.procfs=/host/proc\"\n      - \"--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\"\n      - \"--no-collector.ipvs\"\n    ports:\n      - \"9100:9100\"\n    volumes:\n      - /proc:/host/proc:ro\n      - /sys:/host/sys:ro\n    networks:\n      - monitoring\n    deploy:\n      mode: global   # one per node\n\nconfigs:\n  prometheus_config:\n    file: ./prometheus/prometheus.yaml\n</code></pre>"},{"location":"2-project/setup/#2-prometheusprometheusyaml","title":"2. <code>prometheus/prometheus.yaml</code>","text":"<pre><code>global:\n  scrape_interval: 30s\n  evaluation_interval: 30s\n\nscrape_configs:\n  - job_name: 'node-exporter'\n    dns_sd_configs:\n      - names: ['tasks.node-exporter']\n        type: A\n        port: 9100\n\n  - job_name: 'cadvisor'\n    dns_sd_configs:\n      - names: ['tasks.cadvisor']\n        type: A\n        port: 8080\n\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: [\"prometheus:9090\"]\n</code></pre> <p>\ud83d\udc49 Notice:</p> <ul> <li>Instead of hardcoding <code>10.1.149.x</code> IPs, we use <code>tasks.&lt;service&gt;</code> DNS for Swarm service discovery.</li> <li>This way, Prometheus automatically finds all replicas on all nodes.</li> </ul>"},{"location":"2-project/setup/#step-by-step-setup","title":"\ud83d\udee0 Step-by-Step Setup","text":""},{"location":"2-project/setup/#1-initialize-swarm_1","title":"1. Initialize Swarm","text":"<p>On your manager node (your single machine is enough for practice):</p> <pre><code>docker swarm init\n</code></pre>"},{"location":"2-project/setup/#2-create-directories","title":"2. Create directories","text":"<p>On the manager:</p> <pre><code>mkdir -p monitoring/grafana/grafana-volume\nmkdir -p monitoring/prometheus\n</code></pre> <p>Copy the two files:</p> <ul> <li><code>docker-compose.yaml</code> \u2192 <code>monitoring/docker-compose.yaml</code></li> <li><code>prometheus.yaml</code> \u2192 <code>monitoring/prometheus/prometheus.yaml</code></li> </ul>"},{"location":"2-project/setup/#3-deploy-the-stack","title":"3. Deploy the stack","text":"<p>From the <code>monitoring/</code> directory:</p> <pre><code>docker stack deploy -c docker-compose.yaml monitoring\n</code></pre>"},{"location":"2-project/setup/#4-verify","title":"4. Verify","text":"<pre><code>docker stack ls\ndocker service ls\ndocker service ps monitoring_prometheus\ndocker service ps monitoring_cadvisor\n</code></pre>"},{"location":"2-project/setup/#5-access-dashboards","title":"5. Access dashboards","text":"<ul> <li>Grafana \u2192 http://localhost:3000 (<code>admin/admin</code>)</li> <li>Prometheus \u2192 http://localhost:9090</li> <li>Query <code>up</code> in Prometheus \u2192 you\u2019ll see node-exporter + cadvisor for all swarm nodes.</li> </ul>"},{"location":"2-project/setup/#6-import-grafana-dashboards","title":"6. Import Grafana dashboards","text":"<ul> <li>Add Prometheus as a datasource \u2192 <code>http://prometheus:9090</code>.</li> <li> <p>Import dashboards:</p> </li> <li> <p>Node Exporter Full (ID: 1860)</p> </li> <li>Docker &amp; cAdvisor (ID: 893)</li> </ul>"},{"location":"2-project/setup/#end-result","title":"\u2705 End Result","text":"<ul> <li>Node Exporter (global service) \u2192 1 instance per node.</li> <li>cAdvisor (global service) \u2192 1 instance per node.</li> <li>Prometheus scrapes all automatically via DNS.</li> <li>Grafana visualizes with ready-made dashboards.</li> </ul> <p>\u26a1 Now you can add any app as a Swarm service, and Prometheus can scrape it with the same <code>tasks.&lt;service&gt;</code> trick.</p>"},{"location":"2-project/setup/#validation","title":"Validation","text":"<p>Run:</p> <pre><code>docker service ls\n</code></pre> <p>If all the services are finally running cleanly we should see</p> <pre><code>monitoring_cadvisor         global       1/1  \nmonitoring_grafana          replicated   1/1  \nmonitoring_nginx-app        replicated   1/1  \nmonitoring_nginx-exporter   replicated   1/1  \nmonitoring_node-exporter    global       1/1  \nmonitoring_prometheus       replicated   1/1  \n</code></pre> <p>That means:</p> <ul> <li>\u2705 Grafana is up (<code>http://localhost:3000</code>)</li> <li>\u2705 Prometheus is up (<code>http://localhost:9090</code>)</li> <li>\u2705 Node Exporter is running per node (<code>:9100</code>)</li> <li>\u2705 cAdvisor is running per node (<code>:8080</code>)</li> <li>\u2705 Nginx app is reachable (<code>http://localhost:8081</code>)</li> <li>\u2705 Nginx Prometheus Exporter is running (<code>http://localhost:9113/metrics</code>)</li> </ul>"},{"location":"2-project/setup/#next-steps-to-confirm-everything","title":"\ud83d\udd0e Next steps (to confirm everything)","text":"<ol> <li>Check Nginx <code>stub_status</code>:</li> </ol> <pre><code>curl http://localhost:8081/stub_status\n</code></pre> <p>You should see output like:</p> <pre><code>Active connections: 1\nserver accepts handled requests\n 3 3 3\nReading: 0 Writing: 1 Waiting: 0\n</code></pre> <ol> <li>Check Nginx Exporter metrics:</li> </ol> <pre><code>curl http://localhost:9113/metrics | grep nginx\n</code></pre> <p>Should show metrics like:</p> <pre><code>nginx_http_requests_total{host=\"...\",}  10\nnginx_connections_active  1\nnginx_connections_accepted 3\n</code></pre> <ol> <li> <p>Check Prometheus targets:    Open http://localhost:9090/targets    You should see:</p> </li> <li> <p><code>node-exporter</code> targets (one per node)</p> </li> <li><code>cadvisor</code> targets (one per node)</li> <li><code>prometheus</code> itself</li> <li> <p><code>nginx</code> exporter target (<code>9113</code>)</p> </li> <li> <p>Import Grafana dashboards:</p> </li> <li> <p>Prometheus datasource: <code>http://prometheus:9090</code></p> </li> <li> <p>Useful dashboards:</p> <ul> <li>Node Exporter Full \u2192 1860</li> <li>Docker &amp; cAdvisor \u2192 893</li> <li>Nginx Prometheus Exporter \u2192 12708</li> </ul> </li> </ol> <p>\u26a1 If all those checks succeed, your full monitoring stack is good to go: infra + containers + Nginx app.</p>"},{"location":"2-project/swarm/","title":"Docker Swarm","text":""},{"location":"2-project/swarm/#what-is-docker-swarm","title":"\ud83d\udc33 What is Docker Swarm?","text":"<p>Docker Swarm (aka Swarm mode) is Docker Engine\u2019s built-in container orchestrator. It turns a group of Docker hosts into a fault-tolerant cluster, letting you run containers as services with rolling updates, self-healing, service discovery, and secure networking\u2014using the same Docker CLI you already know.</p> <p>\ud83d\udc49 If Docker is how you run a container, Swarm is how you run containers in production across multiple machines.</p>"},{"location":"2-project/swarm/#why-do-we-need-swarm","title":"\ud83e\uddd0 Why Do We Need Swarm?","text":"<p>Modern apps need scale, resilience, and zero-downtime updates:</p> <ul> <li>Keep N replicas running\u2014auto-replace failed ones.</li> <li>Distribute workloads across nodes.</li> <li>Expose services behind cluster IP + load balancing.</li> <li>Update safely (canary/rolling) and roll back on failure.</li> <li>Secure inter-node comms (mTLS) and handle secrets.</li> </ul> <p>Swarm delivers these with simple, Docker-native workflows.</p>"},{"location":"2-project/swarm/#how-swarm-works-core-ideas","title":"\ud83d\udd27 How Swarm Works (Core Ideas)","text":"<ul> <li> <p>Node \u2014 a Docker host in the cluster.</p> </li> <li> <p>Manager nodes maintain Raft state &amp; schedule tasks.</p> </li> <li>Worker nodes run tasks (container instances).</li> <li> <p>Service \u2014 desired state (image, replicas, ports, constraints).</p> </li> <li> <p>Task \u2014 one running container for a service.</p> </li> <li>Modes \u2014 <code>replicated</code> (N copies) or <code>global</code> (1 per node).</li> <li>Overlay networks \u2014 multi-host virtual networks with built-in service discovery (<code>DNS</code>), VIP load-balancing, optional encryption.</li> <li>Routing Mesh \u2014 publishes ports on every node, forwards to healthy tasks.</li> <li>Secrets &amp; Configs \u2014 securely distribute small files to services.</li> <li>Stacks \u2014 app bundles defined with Compose v3 (<code>docker stack</code>).</li> </ul>"},{"location":"2-project/swarm/#architecture-overview","title":"\ud83d\udd17 Architecture Overview","text":"<pre><code>+-------------------+           +-------------------+           +-------------------+\n|   Manager Node    |  mTLS     |   Manager Node    |  mTLS     |   Manager Node    |\n|  - Raft consensus |&lt;---------&gt;|  - Scheduling     |&lt;---------&gt;|  - CA/Cert rotate |\n+---------+---------+           +---------+---------+           +---------+---------+\n          |                                 |                               |\n          v                                 v                               v\n   +------+-------+                  +------+-------+                +------+-------+\n   |  Worker Node |                  |  Worker Node |                |  Worker Node |\n   |  Tasks/Pods  |                  |  Tasks/Pods  |                |  Tasks/Pods  |\n   +------+-------+                  +------+-------+                +------+-------+\n          \\___________________ Overlay Networks (VXLAN, optional encryption) ______/\n</code></pre>"},{"location":"2-project/swarm/#control-data-flow","title":"\ud83d\udd04 Control &amp; Data Flow","text":"<pre><code>sequenceDiagram\n    participant CLI as docker CLI\n    participant MGR as Manager (Raft)\n    participant NW as Overlay Net + VIP\n    participant T as Service Tasks\n\n    CLI-&gt;&gt;MGR: docker service update --image app:v2\n    MGR--&gt;&gt;MGR: Plan rolling update (update_config)\n    MGR-&gt;&gt;T: Replace tasks (start-first/stop-first)\n    T--&gt;&gt;MGR: Health OK (or failure)\n    MGR-&gt;&gt;NW: Update VIP backends\n    CLI--&gt;&gt;MGR: docker service ps app</code></pre>"},{"location":"2-project/swarm/#quickstart","title":"\ud83e\uddf0 Quickstart","text":""},{"location":"2-project/swarm/#1-initialize-a-swarm-first-manager","title":"1) Initialize a Swarm (first manager)","text":"<pre><code># on node A\ndocker swarm init --advertise-addr &lt;MANAGER_IP&gt;\n</code></pre> <p>Grab the printed join token.</p>"},{"location":"2-project/swarm/#2-join-more-nodes","title":"2) Join more nodes","text":"<pre><code># on nodes B, C ...\ndocker swarm join --token &lt;worker-token&gt; &lt;MANAGER_IP&gt;:2377\n\n# (optional) join more managers\ndocker swarm join --token &lt;manager-token&gt; &lt;MANAGER_IP&gt;:2377\n</code></pre>"},{"location":"2-project/swarm/#3-create-a-service","title":"3) Create a service","text":"<pre><code>docker service create --name web --replicas 3 -p 80:80 nginx:alpine\ndocker service ls\ndocker service ps web\n</code></pre>"},{"location":"2-project/swarm/#4-scale-update-roll-back","title":"4) Scale / Update / Roll back","text":"<pre><code>docker service scale web=6\ndocker service update --image nginx:1.27 --update-order start-first web\ndocker service rollback web\n</code></pre>"},{"location":"2-project/swarm/#stacks-with-compose-v3","title":"\ud83e\uddf1 Stacks with Compose (v3+)","text":""},{"location":"2-project/swarm/#docker-composeyml","title":"docker-compose.yml","text":"<pre><code>version: \"3.9\"\n\nservices:\n  api:\n    image: ghcr.io/acme/api:1.2.3\n    ports:\n      - target: 8080\n        published: 8080\n        protocol: tcp\n        mode: ingress   # or host\n    networks: [appnet]\n    deploy:\n      replicas: 4\n      update_config:\n        parallelism: 1\n        order: start-first\n        delay: 10s\n        failure_action: rollback\n      rollback_config:\n        parallelism: 2\n      restart_policy:\n        condition: on-failure\n        delay: 3s\n        max_attempts: 3\n      resources:\n        limits:\n          cpus: \"1.0\"\n          memory: 512M\n        reservations:\n          cpus: \"0.25\"\n          memory: 128M\n      placement:\n        constraints:\n          - node.role == worker\n          - node.labels.zone == eu-central\n        preferences:\n          - spread: node.labels.az\n\n  worker:\n    image: ghcr.io/acme/worker:2.0\n    deploy:\n      mode: global\n    networks: [appnet]\n\nnetworks:\n  appnet:\n    driver: overlay\n    attachable: true\n</code></pre> <p>Deploy:</p> <pre><code>docker stack deploy -c docker-compose.yml acme\ndocker stack ls\ndocker stack services acme\ndocker stack ps acme\ndocker stack rm acme\n</code></pre>"},{"location":"2-project/swarm/#networking-in-swarm","title":"\ud83c\udf10 Networking in Swarm","text":"<ul> <li>Service Discovery: each service gets DNS (<code>tasks.&lt;name&gt;</code>) and a VIP (virtual IP).</li> <li>Load Balancing: VIP distributes L4 traffic across healthy tasks.</li> <li> <p>Routing Mesh (ingress):</p> </li> <li> <p><code>-p 80:80</code> exposes on all nodes; any node forwards to a task.</p> </li> <li>Use <code>mode: host</code> (or CLI <code>--publish mode=host</code>) to expose only on the node where a task runs.</li> <li> <p>Overlay Networks:</p> </li> <li> <p>Create: <code>docker network create -d overlay --attachable appnet</code></p> </li> <li>Encrypt overlay: <code>docker network create -d overlay --opt encrypted secure-net</code></li> </ul> <p>Ports to open between nodes</p> <ul> <li><code>2377/tcp</code> (cluster management), <code>7946/tcp+udp</code> (gossip), <code>4789/udp</code> (VXLAN).</li> <li>Published service ports (your choice).</li> </ul>"},{"location":"2-project/swarm/#security-model","title":"\ud83d\udd12 Security Model","text":"<ul> <li>Mutual TLS between nodes by default (built-in CA, automatic cert rotation).</li> <li>Raft log on managers is encrypted; back up the state.</li> <li>Auto-lock (optional): requires unlock key on daemon restart (<code>docker swarm update --autolock=true</code>).</li> <li> <p>Secrets &amp; Configs:</p> </li> <li> <p>Create: <code>docker secret create db_pass -</code> then paste.</p> </li> <li>Mounted in containers at <code>/run/secrets/&lt;name&gt;</code> (tmpfs).</li> <li>Configs similar, mounted read-only (often under <code>/</code>).</li> <li>Keep \u2014ideal for creds, certs, small config files."},{"location":"2-project/swarm/#updates-health-self-healing","title":"\ud83d\udd01 Updates, Health &amp; Self-Healing","text":"<ul> <li>Rolling updates with <code>update_config</code> (parallelism, delay, failure_action).</li> <li>Update order: <code>start-first</code> (zero-downtime) or <code>stop-first</code>.</li> <li>Healthchecks in your Dockerfile/Compose gate promotions.</li> <li>Restart policies (<code>on-failure</code>, <code>any</code>, <code>none</code>).</li> <li>Automatic rescheduling of failed tasks to healthy nodes.</li> </ul>"},{"location":"2-project/swarm/#persistent-storage","title":"\ud83d\udce6 Persistent Storage","text":"<p>Containers are ephemeral; tasks may move. Use:</p> <ul> <li>Remote/shared volumes (e.g., NFS, SMB, Ceph, Portworx, etc.) via volume plugins.</li> <li>Or pin stateful services with constraints to labeled nodes that host the data.</li> <li>Avoid default local volumes for movable services unless you accept data locality.</li> </ul>"},{"location":"2-project/swarm/#logs-metrics","title":"\ud83d\udcc8 Logs &amp; Metrics","text":"<ul> <li><code>docker service logs &lt;svc&gt;</code> (depends on chosen logging driver).</li> <li>Drivers: <code>json-file</code>, <code>journald</code>, <code>syslog</code>, <code>gelf</code>, <code>fluentd</code>, <code>awslogs</code>, etc.</li> <li>Node/cluster events: <code>docker events</code> and <code>docker inspect</code> for deep dives.</li> </ul>"},{"location":"2-project/swarm/#placement-scheduling","title":"\ud83d\uddfa\ufe0f Placement &amp; Scheduling","text":"<ul> <li> <p>Constraints (hard rules): <code>node.role == worker</code>, <code>node.labels.disk == ssd</code>.</p> </li> <li> <p>Label nodes: <code>docker node update --label-add disk=ssd &lt;node&gt;</code></p> </li> <li>Preferences (soft rules): spread by <code>node.labels.az</code> to balance failure domains.</li> <li>Resources: set reservations/limits so the scheduler makes good decisions.</li> </ul>"},{"location":"2-project/swarm/#service-types","title":"\ud83e\uddea Service Types","text":"<ul> <li>Replicated \u2014 run N copies across the cluster.</li> <li>Global \u2014 run 1 copy per eligible node (great for agents/daemons).</li> <li>DNS round-robin \u2014 skip VIP with <code>endpoint_mode: dnsrr</code> (hand control to app-level LB).</li> </ul>"},{"location":"2-project/swarm/#operations-playbook","title":"\ud83e\udded Operations Playbook","text":"<p>Managers &amp; quorum</p> <ul> <li>Use odd number of managers: \u2157/7.</li> <li>Tolerates <code>\u230a(N-1)/2\u230b</code> failures (e.g., 3 managers \u2192 tolerate 1 down).</li> <li>Avoid running workloads on managers; set <code>availability drain</code>.</li> </ul> <p>Upgrades</p> <pre><code>docker node update --availability drain &lt;node&gt;\n# upgrade Docker, reboot, etc.\ndocker node update --availability active &lt;node&gt;\n</code></pre> <p>Backups</p> <pre><code># On a manager (and when cluster is healthy):\n# Save /var/lib/docker/swarm (Raft) while engine is stopped or via documented snapshot method.\n</code></pre> <p>Common checks</p> <pre><code>docker node ls\ndocker node ps &lt;node&gt;\ndocker service ps &lt;svc&gt; --no-trunc\ndocker service inspect &lt;svc&gt; --pretty\ndocker network inspect &lt;net&gt;\n</code></pre>"},{"location":"2-project/swarm/#limitations-watch-outs","title":"\u26a0\ufe0f Limitations &amp; Watch-Outs","text":"<ul> <li>No built-in horizontal auto-scaling (need external tooling).</li> <li>Stateful workloads require deliberate storage design.</li> <li>Routing Mesh is L4 only; advanced L7 needs a proxy (Traefik, Nginx, HAProxy).</li> <li>Smaller ecosystem vs Kubernetes; fewer controllers/operators.</li> <li>Cross-cloud WAN clusters can be finicky (latency, firewalls, MTU).</li> </ul>"},{"location":"2-project/swarm/#swarm-vs-compose-vs-kubernetes","title":"\ud83e\udd4a Swarm vs Compose vs Kubernetes","text":"Use Case Compose (single host) Swarm Kubernetes Scope Dev, single VM Small\u2013mid prod clusters Mid\u2013large prod HA &amp; Scheduling \u274c \u2705 (simple) \u2705 (rich) Rolling updates \u26a0\ufe0f (limited) \u2705 \u2705 Auto-scaling \u274c \u274c \u2705 Ecosystem/Extensibility Low Medium High Complexity Low Low\u2013Med High"},{"location":"2-project/swarm/#example-secrets-encrypted-overlay","title":"\ud83d\udd10 Example: Secrets + Encrypted Overlay","text":"<pre><code># network with encryption\ndocker network create -d overlay --opt encrypted prod-net\n\n# secret\nprintf 's3cr3tP@ss' | docker secret create db_password -\n\n# compose snippet\ncat &gt; stack.yml &lt;&lt;'YAML'\nversion: \"3.9\"\nservices:\n  db:\n    image: postgres:16\n    networks: [prod-net]\n    secrets: [db_password]\n    environment:\n      POSTGRES_PASSWORD_FILE: /run/secrets/db_password\n    deploy:\n      placement:\n        constraints: [ \"node.labels.role == db\" ]\n      restart_policy: { condition: on-failure }\nnetworks:\n  prod-net: { driver: overlay }\nsecrets:\n  db_password: { external: true }\nYAML\n\ndocker stack deploy -c stack.yml data\n</code></pre>"},{"location":"2-project/swarm/#swarm-cheat-sheet","title":"\ud83e\uddfe Swarm Cheat Sheet","text":""},{"location":"2-project/swarm/#cluster","title":"Cluster","text":"<pre><code>docker swarm init | join | leave --force\ndocker node ls | inspect | update --label-add team=payments &lt;node&gt;\ndocker node update --availability drain|active &lt;node&gt;\n</code></pre>"},{"location":"2-project/swarm/#services","title":"Services","text":"<pre><code>docker service create --name api --replicas 3 -p 8080:8080 ghcr.io/acme/api:1.0\ndocker service ls | ps api | logs -f api\ndocker service scale api=8\ndocker service update --image ghcr.io/acme/api:1.1 --update-order start-first api\ndocker service rollback api\n</code></pre>"},{"location":"2-project/swarm/#stacks","title":"Stacks","text":"<pre><code>docker stack deploy -c docker-compose.yml app\ndocker stack services app\ndocker stack ps app\ndocker stack rm app\n</code></pre>"},{"location":"2-project/swarm/#networks-secrets","title":"Networks &amp; Secrets","text":"<pre><code>docker network create -d overlay --attachable appnet\ndocker secret create tls_key key.pem\ndocker config create app_conf app.ini\n</code></pre>"},{"location":"2-project/swarm/#common-patterns","title":"\ud83e\uddea Common Patterns","text":"<ul> <li>Blue-green: run <code>app_v1</code> and <code>app_v2</code> with different published ports; swap LB.</li> <li>Canary: temporarily scale a <code>:next</code> version to 5\u201310% of replicas via constraints.</li> <li>Node pinning: place GPU jobs with <code>node.labels.gpu == true</code>.</li> <li>Sidecar: run log shippers or metrics collectors as global services.</li> </ul>"},{"location":"2-project/swarm/#troubleshooting-tips","title":"\ud83e\uddef Troubleshooting Tips","text":"<ul> <li>Task flapping? Check healthchecks &amp; <code>restart_policy</code>.</li> <li>No connectivity? Verify firewall ports <code>2377</code>, <code>7946</code>, <code>4789</code> and MTU.</li> <li>VIP oddities? Try <code>endpoint_mode: dnsrr</code> or <code>--publish mode=host</code>.</li> <li>Overlay issues? Ensure consistent subnet ranges and <code>iptables</code> not blocking VXLAN.</li> <li>Quorum lost? Do not force-new-cluster casually; restore from backup.</li> </ul>"},{"location":"2-project/swarm/#final-takeaway","title":"\ud83c\udfaf Final Takeaway","text":"<p>Docker Swarm gives you simple, secure, Docker-native orchestration:</p> <ul> <li>\u2705 Easy to learn (Docker CLI/Compose).</li> <li>\u2705 Built-in mTLS, service discovery, rolling updates, self-healing.</li> <li>\u2705 Great fit for small\u2013medium clusters and teams prioritizing simplicity.</li> </ul> <p>Design storage thoughtfully, keep odd manager counts, and use stacks + overlay networks to ship reliable apps with minimal overhead.</p>"},{"location":"2-project/swarm/#cheat-sheet","title":"\ud83d\udc33 Cheat Sheet","text":"<pre><code># Initialize Swarm on the first node\ndocker swarm init\n\n# Get join token for workers\ndocker swarm join-token worker\n\n# Get join token for managers\ndocker swarm join-token manager\n\n# Join a worker/manager node to the cluster\ndocker swarm join --token &lt;TOKEN&gt; &lt;MANAGER-IP&gt;:2377\n</code></pre>"},{"location":"2-project/swarm/#stack-deployment","title":"\ud83d\udce6 Stack Deployment","text":"<pre><code># Deploy the stack (monitoring here is the stack name)\ndocker stack deploy -c docker-compose.yml monitoring\n\n# List stacks\ndocker stack ls\n\n# List services in the stack\ndocker stack services monitoring\n\n# List running tasks (replicas) for a service\ndocker service ps monitoring_prometheus\n</code></pre>"},{"location":"2-project/swarm/#service-management","title":"\u2699\ufe0f Service Management","text":"<pre><code># Scale a service (e.g., run 5 replicas of nginx-app)\ndocker service scale monitoring_nginx-app=5\n\n# Update a service (e.g., rolling restart)\ndocker service update --force monitoring_prometheus\n\n# Remove a service\ndocker service rm monitoring_nginx-app\n</code></pre>"},{"location":"2-project/swarm/#container-node-debugging","title":"\ud83d\udc33 Container &amp; Node Debugging","text":"<pre><code># List all swarm nodes\ndocker node ls\n\n# Inspect details about a node\ndocker node inspect &lt;NODE-ID&gt; --pretty\n\n# Show running containers on this node\ndocker ps\n\n# Exec into a running container\ndocker exec -it &lt;CONTAINER-ID&gt; sh\n\n# Show logs from a service (aggregates all tasks)\ndocker service logs monitoring_prometheus\n\n# Show logs from one container\ndocker logs &lt;CONTAINER-ID&gt;\n</code></pre>"},{"location":"2-project/swarm/#prometheus-grafana","title":"\ud83d\udcca Prometheus &amp; Grafana","text":"<pre><code># Access Prometheus UI\nhttp://localhost:9090\n\n# Access Grafana UI\nhttp://localhost:3000  (default admin/admin if not changed)\n\n# Prometheus test query\nup\n\n# Check which targets are being scraped\nhttp://localhost:9090/targets\n</code></pre>"},{"location":"2-project/swarm/#prometheus-config-reload","title":"\ud83d\udee0 Prometheus Config Reload","text":"<p>Prometheus doesn\u2019t auto-reload config in Swarm unless restarted:</p> <pre><code># Force service to reload config (rolling update)\ndocker service update --force monitoring_prometheus\n</code></pre>"},{"location":"2-project/swarm/#cleanup","title":"\ud83e\uddf9 Cleanup","text":"<pre><code># Remove the whole stack\ndocker stack rm monitoring\n\n# Leave the swarm (on workers)\ndocker swarm leave\n\n# Leave the swarm (on manager, forcefully)\ndocker swarm leave --force\n</code></pre> <p>\u26a1 With just these commands you can:</p> <ul> <li>Stand up your monitoring stack</li> <li>Scale apps</li> <li>Debug targets in Prometheus</li> <li>Import Grafana dashboards</li> </ul>"},{"location":"2-project/tasks/0-overview/","title":"Overview","text":"<p>This Taskfile defines automation tasks to simplify development workflows and ensure consistency across environments.</p> <p>It abstracts repetitive shell commands into named tasks you can run with:</p> <pre><code>task &lt;task-name&gt; # runs a task\n</code></pre> <p>You can list all available tasks with:</p> <pre><code>task --list-all\n</code></pre> <p>For detailed details about taskfile use:</p> <ul> <li>Main Taskfile</li> <li>GitFlow Taskfile</li> </ul>"},{"location":"2-project/tasks/0-overview/#contact","title":"\ud83d\udcec Contact","text":"<p>Questions or issues with GitFlow setup? Reach out via GitHub Issues or email at your.email@example.com.</p>"},{"location":"2-project/tasks/1-main-taskfile/","title":"\ud83e\uddf0 Main Taskfile Overview","text":"<p>This section describes the purpose and layout of the main <code>Taskfile.yml</code> used in this project. The Taskfile defines automation tasks to simplify development workflows and ensure consistency across environments.</p>"},{"location":"2-project/tasks/1-main-taskfile/#purpose-of-this-taskfile","title":"\u2699\ufe0f Purpose of This Taskfile","text":"<p>This Taskfile provides command-line shortcuts for tasks like:</p> <ul> <li>Project setup</li> <li>Development environment bootstrapping</li> <li>Application deployment</li> <li>Local documentation serving</li> <li>Cleanup and teardown</li> </ul> <p>It abstracts repetitive shell commands into named tasks you can run with:</p> <pre><code>task &lt;task-name&gt;\n</code></pre>"},{"location":"2-project/tasks/1-main-taskfile/#core-sections","title":"\ud83e\uddf1 Core Sections","text":""},{"location":"2-project/tasks/1-main-taskfile/#1-setup-initialization","title":"1. Setup &amp; Initialization","text":"<p>Includes tasks for:</p> <ul> <li>Installing dependencies</li> <li>Setting up local development tools</li> <li>Generating keys or configs (if applicable)</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#2-development-workflow","title":"2. Development Workflow","text":"<p>Common tasks for:</p> <ul> <li>Starting local services or dev containers</li> <li>Running dev servers</li> <li>Applying Kubernetes configs or local manifests</li> <li>Watching for file changes</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#3-documentation","title":"3. Documentation","text":"<p>Tasks to:</p> <ul> <li>Serve documentation locally (e.g., MkDocs)</li> <li>Build or deploy docs (if using GitHub Pages or mike)</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#4-deployment-automation","title":"4. Deployment &amp; Automation","text":"<p>Tasks may automate:</p> <ul> <li>Building and pushing Docker images</li> <li>Running linters or formatters</li> <li>Applying infrastructure changes (e.g., with Terraform)</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#5-cleanup-teardown","title":"5. Cleanup &amp; Teardown","text":"<p>Includes safe commands to:</p> <ul> <li>Tear down local clusters or containers</li> <li>Remove generated files or environments</li> <li>Reset state for fresh runs</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#typical-usage-flow","title":"\ud83e\uddea Typical Usage Flow","text":"<p>A typical flow using this Taskfile might look like:</p> <ul> <li>Set up your environment:</li> </ul> <pre><code>task setup\n</code></pre> <ul> <li>Start development:</li> </ul> <pre><code>task dev\n</code></pre> <ul> <li>Serve documentation:</li> </ul> <pre><code>task docs\n</code></pre> <ul> <li>Clean up:</li> </ul> <pre><code>task cleanup\n</code></pre>"},{"location":"2-project/tasks/1-main-taskfile/#notes","title":"\ud83d\udcdd Notes","text":"<ul> <li>To list all available tasks:</li> </ul> <pre><code>task --list-all\n</code></pre> <ul> <li>Variables and flags can be passed to tasks like so:</li> </ul> <pre><code>task my-task &lt;var&gt;=&lt;value&gt;\n</code></pre> <ul> <li>You can structure task dependencies using <code>deps:</code> and reuse shell logic cleanly across environments.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#tips","title":"\ud83d\udcdd Tips","text":"Key Description dotenv + env: auto-load .env files and allow task-specific overrides. vars: static or dynamic variables (via shell) for templated substitution. prompt: even for setup or prod, ask user before proceeding. preconditions: enforce environment state before running. deps: define ordering (serial) via deps for safety and repeatability. internal: hide helper tasks from user listings. platforms: restrict tasks to specific OS/arch. requires: enforce required input variables. status: skip tasks if outputs already exist."},{"location":"2-project/tasks/1-main-taskfile/#related-docs","title":"\ud83d\udd17 Related Docs","text":"<ul> <li>GitFlow Taskfile</li> <li>Getting Started</li> <li>Architecture Overview</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#contact","title":"\ud83d\udcec Contact","text":"<p>For issues or suggestions related to automation and task structure, open an issue or contact the maintainer at seannjela@outlook.com.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/","title":"\ud83d\udd00 GitFlow Taskfile Overview","text":"<p>This page explains the structure and functionality of the <code>Taskfile.gitflow.yml</code> file, which automates a standardized Git workflow using Git Flow conventions. This taskfile is designed to simplify and formalize branching, releasing, and hotfixing in projects that follow the GitFlow methodology.</p> <p>It is optional to use gitflow.</p> <p>If you do not want to use it, you can remove the <code>Taskfile.gitflow.yml</code> file and unlink it from the <code>Taskfile.yaml</code> file (remove the <code>includes</code> section). If you cannot find the section use <code>CTRL + F</code> to search for Taskfile.yaml.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#what-is-git-flow","title":"\ud83d\udce6 What is Git Flow?","text":"<p>Git Flow is a branching strategy that separates feature development from production releases. It introduces long-lived branches like <code>main</code> and <code>develop</code>, as well as temporary branches for features, releases, and hotfixes.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#purpose-of-this-taskfile","title":"\u2699\ufe0f Purpose of This Taskfile","text":"<p>The <code>Taskfile.gitflow.yml</code> automates repetitive Git Flow actions using the <code>task</code> CLI tool. It allows you to:</p> <ul> <li>Initialize a Git Flow structure with default branches and prefixes</li> <li>Create and finish feature branches</li> <li>Create release and hotfix branches</li> <li>Push and merge code with consistent naming and flow</li> <li>Eliminate manual mistakes in branch naming or merging</li> </ul> <p>This is especially useful in teams or long-running solo projects where structured release cycles are important.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#what-this-taskfile-automates","title":"\ud83e\udde9 What This Taskfile Automates","text":"<p>Here\u2019s a breakdown of what\u2019s covered:</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#1-initialization","title":"1. Initialization","text":"<ul> <li>Sets up Git Flow with <code>main</code> as the production branch and <code>develop</code> for ongoing work.</li> <li>Configures standard prefixes (<code>feature/</code>, <code>release/</code>, <code>hotfix/</code>, etc.).</li> <li>Ensures required branches (<code>main</code>, <code>develop</code>) exist locally and remotely.</li> <li>Optionally initializes the <code>gh-pages</code> branch for documentation deployments.</li> </ul> <p>This is typically run once at the start of the project using <code>task -t Taskfile.gitflow.yml init</code>.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#2-feature-branch-management","title":"2. Feature Branch Management","text":"<ul> <li>Start a new feature branch from <code>develop</code></li> <li>Finish a feature by merging it back into <code>develop</code></li> <li>Automatically push changes to the remote</li> <li>Prevents common mistakes like forgetting to push or rebase</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#3-release-branch-management","title":"3. Release Branch Management","text":"<ul> <li>Create a release branch off <code>develop</code></li> <li>Optionally tag a version</li> <li>Merge into <code>main</code> and <code>develop</code></li> <li>Clean up the release branch</li> <li>Pushes changes and tags to the remote</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#4-hotfix-branch-management","title":"4. Hotfix Branch Management","text":"<ul> <li>Create a hotfix directly off <code>main</code> (for production issues)</li> <li>Merge back into both <code>main</code> and <code>develop</code></li> <li>Optionally tag the hotfix release</li> <li>Push changes and remove local branches</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#5-branch-cleanup-and-syncing","title":"5. Branch Cleanup and Syncing","text":"<ul> <li>Deletes local feature/release branches after merging</li> <li>Pulls and syncs remote branches as needed</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#typical-usage-flow","title":"\ud83d\uddc2 Typical Usage Flow","text":"<ol> <li> <p>Initialize GitFlow structure <pre><code>task init\n</code></pre></p> </li> <li> <p>Start a new feature <pre><code>task feature:start name=\"add-login\"\n</code></pre></p> </li> <li> <p>Finish a feature <pre><code>task feature:finish name=\"add-login\"\n</code></pre></p> </li> <li> <p>Start a release <pre><code>task release:start version=\"1.0.0\"\n</code></pre></p> </li> <li> <p>Start a hotfix <pre><code>task hotfix:start version=\"1.0.1\"\n</code></pre></p> </li> <li> <p>Finish a release <pre><code>task release:finish version=\"1.0.0\"\n</code></pre></p> </li> <li> <p>Finish a hotfix <pre><code>task hotfix:finish version=\"1.0.1\"\n</code></pre></p> </li> </ol>"},{"location":"2-project/tasks/2-gitflow-taskfile/#when-should-you-use-this","title":"\ud83e\udde0 When Should You Use This?","text":"<p>Use this taskfile when:</p> <ul> <li>You want consistent branch names and GitFlow discipline</li> <li>You're working in long-lived projects that ship versioned releases</li> <li>You have documentation (e.g. via <code>mike</code>) that needs coordinated tagging</li> <li>You want to automate repetitive Git steps safely</li> </ul> <p>Avoid using it if:</p> <ul> <li>Your workflow is trunk-based (i.e., no <code>develop</code>)</li> <li>You're doing rapid prototyping without versioning</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#notes","title":"\ud83d\udcdd Notes","text":"<ul> <li>This taskfile assumes Git is already initialized and the remote origin is set.</li> <li>It is safe to re-run <code>init</code>; it won\u2019t overwrite existing GitFlow config.</li> <li>The file uses <code>{{.VAR_NAME}}</code> placeholders \u2014 these are defined in the task's command-line usage.</li> <li>You can see available tasks by running:</li> </ul> <pre><code>task --list-all\n</code></pre>"},{"location":"2-project/tasks/2-gitflow-taskfile/#related-docs","title":"\ud83d\udd17 Related Docs","text":"<ul> <li>Main Taskfile Overview</li> <li>Getting Started</li> <li>Architecture</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#contact","title":"\ud83d\udcec Contact","text":"<p>Questions or issues with GitFlow setup? Reach out via GitHub Issues or email at seannjela@outlook.com.</p>"},{"location":"3-troubleshooting/0-overview/","title":"\ud83d\udee0\ufe0f Troubleshooting Guide Overview","text":"<p>Welcome to the troubleshooting section of this documentation. This guide exists to help you diagnose and resolve common issues that may arise while using or setting up this project.</p> <p>Use the search bar at the top of this page to type keywords related to your issue (e.g., docker, cluster, permissions) and quickly find relevant entries.</p>"},{"location":"3-troubleshooting/0-overview/#what-youll-find-here","title":"\ud83d\udcda What You'll Find Here","text":"<p>Each page in this section covers a specific issue or category of problems. These are meant to be: - Concise - Actionable - Focused on real problems encountered during development or deployment</p> <p>You can browse specific problem pages here:</p> <ul> <li>Problem 1</li> <li>Problem 2</li> <li>(More will be added as new issues are documented)</li> </ul> <p>Important Disclaimer</p> <p>This is a personal documentation site. I am maintaining it solo and cannot guarantee that every issue is fully documented or resolved. If you don\u2019t find a solution here, don\u2019t panic \u2014 most tools used in this project (e.g., Docker, Kubernetes, Terraform, Devbox) are widely adopted and well-supported. Try these resources first:</p> <ol> <li>ChatGPT or another AI assistant \u2013 Quick answers and guided debugging  </li> <li>YouTube \u2013 Visual walkthroughs for complex tools or errors  </li> <li>Google \u2013 Forums, GitHub Issues, and StackOverflow posts are often goldmines  </li> </ol>"},{"location":"3-troubleshooting/0-overview/#pro-tip","title":"\ud83e\udde0 Pro Tip","text":"<p>When searching using the search bar above, include the name of the tool or parts of the error message (in quotes if exact), e.g.:</p> <p>\"helm install\" or \"helm\" \"chart not found\" or \"not found\" \"terraform apply\" or \"terraform\" \"invalid provider configuration\" or \"provider not found\" \"kubectl apply\" or \"kubectl\" \"namespace not found\" or \"namespace does not exist\"</p> <p>Thank you for your patience and initiative \u2014 the more we learn from problems, the better this documentation will become.</p>"},{"location":"3-troubleshooting/1-problem1/","title":"\u2757 Problem Title (Short and Specific)","text":"<p>A short one-liner summary of the issue, e.g., \u201cHelm chart fails with \u2018chart not found\u2019 error\u201d.</p>"},{"location":"3-troubleshooting/1-problem1/#context","title":"\ud83e\udded Context","text":"<p>Briefly describe when/where this issue happens: - What tool was being used? - What command was run? - What environment (e.g., Devbox, Docker, local cluster)? - Optional: Any preconditions or relevant setup</p>"},{"location":"3-troubleshooting/1-problem1/#symptoms","title":"\ud83e\udde8 Symptoms","text":"<p>List or describe the symptoms: - Error messages (you can add real output later) - Logs or console behavior - What \"broke\" or stopped working</p>"},{"location":"3-troubleshooting/1-problem1/#possible-causes","title":"\ud83d\udccc Possible Causes","text":"<p>List 1\u20133 likely causes of this issue: - Misconfiguration - Dependency/version mismatch - Network or permissions issue</p>"},{"location":"3-troubleshooting/1-problem1/#resolution-if-available","title":"\u2705 Resolution (If Available)","text":"<p>Leave this blank until you've confirmed a fix.</p>"},{"location":"3-troubleshooting/1-problem1/#workarounds-optional","title":"\ud83e\uddea Workarounds (Optional)","text":"<p>Alternative approaches or partial fixes that helped during debugging.</p>"},{"location":"3-troubleshooting/1-problem1/#external-references","title":"\ud83d\udd17 External References","text":"<p>Useful links, docs, or forum threads: - Stack Overflow Thread - Official Docs - GitHub Issue</p>"},{"location":"3-troubleshooting/1-problem1/#notes","title":"\ud83e\udde0 Notes","text":"<ul> <li>Is this a recurring issue?</li> <li>Does it affect production or just local dev?</li> <li>Can this be caught with a precheck or task later?</li> </ul>"},{"location":"3-troubleshooting/2-problem2/","title":"\u2757 Problem Title (Short and Specific)","text":"<p>A short one-liner summary of the issue, e.g., \u201cHelm chart fails with \u2018chart not found\u2019 error\u201d.</p>"},{"location":"3-troubleshooting/2-problem2/#context","title":"\ud83e\udded Context","text":"<p>Briefly describe when/where this issue happens: - What tool was being used? - What command was run? - What environment (e.g., Devbox, Docker, local cluster)? - Optional: Any preconditions or relevant setup</p>"},{"location":"3-troubleshooting/2-problem2/#symptoms","title":"\ud83e\udde8 Symptoms","text":"<p>List or describe the symptoms: - Error messages (you can add real output later) - Logs or console behavior - What \"broke\" or stopped working</p>"},{"location":"3-troubleshooting/2-problem2/#possible-causes","title":"\ud83d\udccc Possible Causes","text":"<p>List 1\u20133 likely causes of this issue: - Misconfiguration - Dependency/version mismatch - Network or permissions issue</p>"},{"location":"3-troubleshooting/2-problem2/#resolution-if-available","title":"\u2705 Resolution (If Available)","text":"<p>Leave this blank until you've confirmed a fix.</p>"},{"location":"3-troubleshooting/2-problem2/#workarounds-optional","title":"\ud83e\uddea Workarounds (Optional)","text":"<p>Alternative approaches or partial fixes that helped during debugging.</p>"},{"location":"3-troubleshooting/2-problem2/#external-references","title":"\ud83d\udd17 External References","text":"<p>Useful links, docs, or forum threads: - Stack Overflow Thread - Official Docs - GitHub Issue</p>"},{"location":"3-troubleshooting/2-problem2/#notes","title":"\ud83e\udde0 Notes","text":"<ul> <li>Is this a recurring issue?</li> <li>Does it affect production or just local dev?</li> <li>Can this be caught with a precheck or task later?</li> </ul>"},{"location":"4-about/0-about/","title":"\ud83d\udc64 About Me","text":"<p>Dang, you really wanna know huh?</p> <p>I\u2019m Sean Njela, DevOpsSean. I'm a developer, engineer, and lifelong learner documenting my personal and professional projects.</p> <p>This site serves as a central hub for my technical work, built using MkDocs and organized to reflect real-world implementations, lessons learned, and ongoing exploration in areas like DevOps, infrastructure, automation, and system design.</p>"},{"location":"4-about/0-about/#why-this-exists","title":"\ud83c\udfaf Why This Exists","text":"<p>This documentation is part of an ongoing effort to:</p> <ul> <li>Capture complex project setups in a reusable, referenceable format</li> <li>Practice clear technical communication</li> <li>Save future-me from future-headaches</li> <li>Share knowledge with others who might stumble across this work</li> </ul> <p>Whether you're here to learn, debug, borrow ideas, or just browse, you're welcome.</p>"},{"location":"4-about/0-about/#tools-and-tech-i-often-work-with","title":"\ud83e\uddf0 Tools and Tech I Often Work With","text":"<p>Some of the technologies you'll find across these projects:</p> <ul> <li>Containers: Docker, Kubernetes, Kind</li> <li>Infrastructure: Terraform, Helm, Devbox</li> <li>Automation: Taskfile, Make, CI/CD workflows</li> <li>Docs: MkDocs, markdown, GitHub Pages</li> <li>Languages: Python, Bash, YAML</li> </ul> <p>This stack evolves as I experiment and learn \u2014 not every project will use everything.</p>"},{"location":"4-about/0-about/#about-this-site","title":"\ud83d\uddc2 About This Site","text":"<ul> <li>Built with <code>mkdocs-material</code></li> <li>Versioned using <code>mike</code></li> <li>Fully local-first and Git-managed</li> <li>Organized by topic, not tool \u2014 documentation follows the problem or pattern</li> </ul>"},{"location":"4-about/0-about/#contact","title":"\ud83d\udcec Contact","text":"<p>I\u2019m always open to questions, feedback, or conversation:</p> <ul> <li>GitHub: @sean-njela</li> <li>Email: sean.njela@gmail.com</li> <li>Twitter/X: @devopssean</li> </ul> <p>Thanks for visiting \ud83d\ude4f</p>"}]}